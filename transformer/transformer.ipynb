{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "# import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "mp_holistic = mp.solutions.holistic # Holistic model to detect keypoints\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities)\n",
    "print(keras.__version__)\n",
    "# print(keras2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Holistic model with opencv (not required for model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lb/czvphg4j7md8_0znt29m83qc0000gn/T/ipykernel_48420/2247152895.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Detection section\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhoslistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_hand_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_hand_landmarks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/psupr/lib/python3.7/site-packages/mediapipe/python/solutions/holistic.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \"\"\"\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/psupr/lib/python3.7/site-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# output stream names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "FPS = 30\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hoslistic:\n",
    "    while cap.isOpened():\n",
    "        start = time.time()\n",
    "        success, frame = cap.read()\n",
    "        if not success: # if capture frame failed then skip the logic below and retry\n",
    "            continue\n",
    "\n",
    "        # Copy frame\n",
    "        img = frame.copy()\n",
    "        img = cv2.flip(img, 1)\n",
    "        img = cv2.cvtColor(cv2.flip(img,1),cv2.COLOR_BGR2RGB) # Set frame color to RGB to process\n",
    "        # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        # input_img = tf.cast(img, dtype=tf.int32)\n",
    "        img.flags.writeable = False\n",
    "        # Detection section\n",
    "        results = hoslistic.process(img)\n",
    "        if results.left_hand_landmarks:\n",
    "            print(results.left_hand_landmarks)\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) # set back to original color\n",
    "        # draw keypoints to the frame\n",
    "        mp_drawing.draw_landmarks(img,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        # Render keypoints \n",
    "        # loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "        # end = time.time()\n",
    "        # totaltime = end-start\n",
    "        # fps = 1/totaltime\n",
    "        # cv2.putText(img,f'FPS: {int(fps)}',(20,70),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2,cv2.LINE_AA,False)\n",
    "        cv2.imshow('Testing Holistic Model', img)\n",
    "         #This breaks on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "print(\"HERE\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new(results.__new__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmark {\n",
      "  x: 0.4264903664588928\n",
      "  y: 0.48218443989753723\n",
      "  z: -0.8057156801223755\n",
      "  visibility: 0.9999212622642517\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4678216576576233\n",
      "  y: 0.3988126516342163\n",
      "  z: -0.7541573643684387\n",
      "  visibility: 0.9998189210891724\n",
      "}\n",
      "landmark {\n",
      "  x: 0.492043673992157\n",
      "  y: 0.39854589104652405\n",
      "  z: -0.7538420557975769\n",
      "  visibility: 0.9997694492340088\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5114008784294128\n",
      "  y: 0.39861324429512024\n",
      "  z: -0.7539421916007996\n",
      "  visibility: 0.9997957944869995\n",
      "}\n",
      "landmark {\n",
      "  x: 0.41107597947120667\n",
      "  y: 0.4000115692615509\n",
      "  z: -0.7278512120246887\n",
      "  visibility: 0.9998339414596558\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3951709270477295\n",
      "  y: 0.4018693268299103\n",
      "  z: -0.7269402742385864\n",
      "  visibility: 0.9998106360435486\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3797028362751007\n",
      "  y: 0.4051903486251831\n",
      "  z: -0.7271029949188232\n",
      "  visibility: 0.9998696446418762\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5456597805023193\n",
      "  y: 0.4481964409351349\n",
      "  z: -0.4252781271934509\n",
      "  visibility: 0.9998052716255188\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3744216561317444\n",
      "  y: 0.450310081243515\n",
      "  z: -0.2655300498008728\n",
      "  visibility: 0.9998553991317749\n",
      "}\n",
      "landmark {\n",
      "  x: 0.47160062193870544\n",
      "  y: 0.566102921962738\n",
      "  z: -0.6891791224479675\n",
      "  visibility: 0.9998704791069031\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3951500654220581\n",
      "  y: 0.5691022872924805\n",
      "  z: -0.6454452872276306\n",
      "  visibility: 0.9998815655708313\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7209062576293945\n",
      "  y: 0.9243705868721008\n",
      "  z: -0.24583375453948975\n",
      "  visibility: 0.9974647760391235\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2562572658061981\n",
      "  y: 0.9042542576789856\n",
      "  z: -0.1603892296552658\n",
      "  visibility: 0.998978853225708\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8582246899604797\n",
      "  y: 1.4972364902496338\n",
      "  z: -0.2656252086162567\n",
      "  visibility: 0.46728014945983887\n",
      "}\n",
      "landmark {\n",
      "  x: -0.028645429760217667\n",
      "  y: 1.3535434007644653\n",
      "  z: -0.7061036229133606\n",
      "  visibility: 0.9671974182128906\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8176948428153992\n",
      "  y: 1.9423294067382812\n",
      "  z: -0.3506889045238495\n",
      "  visibility: 0.44800251722335815\n",
      "}\n",
      "landmark {\n",
      "  x: 0.20380429923534393\n",
      "  y: 0.6913758516311646\n",
      "  z: -1.4203450679779053\n",
      "  visibility: 0.9776334762573242\n",
      "}\n",
      "landmark {\n",
      "  x: 0.8477339744567871\n",
      "  y: 2.0791642665863037\n",
      "  z: -0.41265711188316345\n",
      "  visibility: 0.4517463743686676\n",
      "}\n",
      "landmark {\n",
      "  x: 0.22252753376960754\n",
      "  y: 0.47567832469940186\n",
      "  z: -1.5927482843399048\n",
      "  visibility: 0.9420904517173767\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7837572693824768\n",
      "  y: 2.060126543045044\n",
      "  z: -0.41462117433547974\n",
      "  visibility: 0.4758422374725342\n",
      "}\n",
      "landmark {\n",
      "  x: 0.25627654790878296\n",
      "  y: 0.469402015209198\n",
      "  z: -1.4540659189224243\n",
      "  visibility: 0.9502986669540405\n",
      "}\n",
      "landmark {\n",
      "  x: 0.7586692571640015\n",
      "  y: 2.017496109008789\n",
      "  z: -0.36957550048828125\n",
      "  visibility: 0.4819613993167877\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2774525284767151\n",
      "  y: 0.5581822991371155\n",
      "  z: -1.397857904434204\n",
      "  visibility: 0.9369670152664185\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5986296534538269\n",
      "  y: 1.9976019859313965\n",
      "  z: -0.11121515184640884\n",
      "  visibility: 0.0017489227466285229\n",
      "}\n",
      "landmark {\n",
      "  x: 0.27306586503982544\n",
      "  y: 1.974215030670166\n",
      "  z: 0.11754634231328964\n",
      "  visibility: 0.0018833499634638429\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5826791524887085\n",
      "  y: 2.894740581512451\n",
      "  z: -0.311114639043808\n",
      "  visibility: 0.0007229038747027516\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2950936555862427\n",
      "  y: 2.869584798812866\n",
      "  z: 0.1349203884601593\n",
      "  visibility: 0.00044003248331137\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5742717385292053\n",
      "  y: 3.693467140197754\n",
      "  z: 0.24404604732990265\n",
      "  visibility: 1.6264972146018408e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2816394865512848\n",
      "  y: 3.6486878395080566\n",
      "  z: 0.5460548996925354\n",
      "  visibility: 3.11109783979191e-06\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5830086469650269\n",
      "  y: 3.8091931343078613\n",
      "  z: 0.2569780945777893\n",
      "  visibility: 1.7698772353469394e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2706106901168823\n",
      "  y: 3.765486240386963\n",
      "  z: 0.5741517543792725\n",
      "  visibility: 7.558655397588154e-06\n",
      "}\n",
      "landmark {\n",
      "  x: 0.5195183157920837\n",
      "  y: 3.9273722171783447\n",
      "  z: -0.41133832931518555\n",
      "  visibility: 2.2134361643111333e-05\n",
      "}\n",
      "landmark {\n",
      "  x: 0.30913016200065613\n",
      "  y: 3.914914608001709\n",
      "  z: -0.09478496015071869\n",
      "  visibility: 4.760431693284772e-05\n",
      "}\n",
      "\n",
      "None\n",
      "landmark {\n",
      "  x: 0.20464473962783813\n",
      "  y: 0.6711519956588745\n",
      "  z: 6.669686740679026e-07\n",
      "}\n",
      "landmark {\n",
      "  x: 0.26448890566825867\n",
      "  y: 0.6405003666877747\n",
      "  z: -0.03659063205122948\n",
      "}\n",
      "landmark {\n",
      "  x: 0.32329729199409485\n",
      "  y: 0.5943821668624878\n",
      "  z: -0.060908690094947815\n",
      "}\n",
      "landmark {\n",
      "  x: 0.37772712111473083\n",
      "  y: 0.580670177936554\n",
      "  z: -0.08379877358675003\n",
      "}\n",
      "landmark {\n",
      "  x: 0.4272077977657318\n",
      "  y: 0.6009045839309692\n",
      "  z: -0.10685556381940842\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2899359464645386\n",
      "  y: 0.38501498103141785\n",
      "  z: -0.03586119785904884\n",
      "}\n",
      "landmark {\n",
      "  x: 0.31932055950164795\n",
      "  y: 0.27222776412963867\n",
      "  z: -0.05819820612668991\n",
      "}\n",
      "landmark {\n",
      "  x: 0.33248916268348694\n",
      "  y: 0.201414555311203\n",
      "  z: -0.07636240124702454\n",
      "}\n",
      "landmark {\n",
      "  x: 0.3414498567581177\n",
      "  y: 0.13791155815124512\n",
      "  z: -0.0902789905667305\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2466227114200592\n",
      "  y: 0.35851550102233887\n",
      "  z: -0.03631703928112984\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2585712671279907\n",
      "  y: 0.22359362244606018\n",
      "  z: -0.05521092563867569\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2637368440628052\n",
      "  y: 0.1393301784992218\n",
      "  z: -0.0714082270860672\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2650850713253021\n",
      "  y: 0.07012471556663513\n",
      "  z: -0.08389153331518173\n",
      "}\n",
      "landmark {\n",
      "  x: 0.2036997526884079\n",
      "  y: 0.36686810851097107\n",
      "  z: -0.0408613421022892\n",
      "}\n",
      "landmark {\n",
      "  x: 0.19508391618728638\n",
      "  y: 0.24512146413326263\n",
      "  z: -0.05895107239484787\n",
      "}\n",
      "landmark {\n",
      "  x: 0.19036665558815002\n",
      "  y: 0.16480521857738495\n",
      "  z: -0.07481981813907623\n",
      "}\n",
      "landmark {\n",
      "  x: 0.18693788349628448\n",
      "  y: 0.0950293242931366\n",
      "  z: -0.08608246594667435\n",
      "}\n",
      "landmark {\n",
      "  x: 0.16141432523727417\n",
      "  y: 0.40314504504203796\n",
      "  z: -0.04921071603894234\n",
      "}\n",
      "landmark {\n",
      "  x: 0.13512876629829407\n",
      "  y: 0.3131614923477173\n",
      "  z: -0.06585487723350525\n",
      "}\n",
      "landmark {\n",
      "  x: 0.11923752725124359\n",
      "  y: 0.25249093770980835\n",
      "  z: -0.07497978955507278\n",
      "}\n",
      "landmark {\n",
      "  x: 0.10825881361961365\n",
      "  y: 0.1917218118906021\n",
      "  z: -0.08102285861968994\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print last frame landmarks\n",
    "print(results.pose_landmarks)\n",
    "print(results.left_hand_landmarks)\n",
    "print(results.right_hand_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of pose landmarks: 33\n"
     ]
    }
   ],
   "source": [
    "# double check the landmarks length\n",
    "print(f'Length of pose landmarks: {len(results.pose_landmarks.landmark)}')\n",
    "# print(f'Length of left hand landmarks: {len(results.left_hand_landmarks.landmark)}') # it will return null if no hand detected\n",
    "# print(f'Length of right hand landmarks: {len(results.right_hand_landmarks.landmark)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keypoints values to array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size should be 258\n"
     ]
    }
   ],
   "source": [
    "# there should be 33 pose(x,y,z,visibility), 21(x,y,z) left hand and 21(x,y,z) right hand landmarks\n",
    "# order should be pose -> left -> right\n",
    "landmarks = np.empty(33*4+21*3+21*3)\n",
    "print(f'size should be {len(landmarks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract pose landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 4)\n",
      "length of pose landmarks 33\n",
      "flattern length of pose landmarks 132\n",
      "(258,)\n"
     ]
    }
   ],
   "source": [
    "pose_landmarks = np.array([[l.x,l.y,l.z,l.visibility] for l in results.pose_landmarks.landmark])\n",
    "print(pose_landmarks.shape)\n",
    "print(f'length of pose landmarks {len(pose_landmarks)}')\n",
    "print(f'flattern length of pose landmarks {len(pose_landmarks.flatten())}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract left hand landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of left hand landmarks 63\n",
      "flattern length of left hand landmarks 63\n"
     ]
    }
   ],
   "source": [
    "lefthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros(21*3)\n",
    "print(f'length of left hand landmarks {len(lefthand_landmarks)}')\n",
    "print(f'flattern length of left hand landmarks {len(lefthand_landmarks.flatten())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract right hand landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of right hand landmarks 21\n",
      "flattern length of right hand landmarks 63\n"
     ]
    }
   ],
   "source": [
    "righthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros(21*3)\n",
    "print(f'length of right hand landmarks {len(righthand_landmarks)}')\n",
    "print(f'flattern length of right hand landmarks {len(righthand_landmarks.flatten())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append to the main landmarks array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258,)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks = np.concatenate([pose_landmarks.flatten(),lefthand_landmarks.flatten(),righthand_landmarks.flatten()])\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypointsToNumPy(results):\n",
    "    pose_landmarks = np.array([[l.x,l.y,l.z,l.visibility] for l in results.pose_landmarks.landmark])\n",
    "    lefthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks and len(results.left_hand_landmarks.landmark)>0 else np.zeros(21*3)\n",
    "    righthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks and len(results.right_hand_landmarks.landmark)>0 else np.zeros(21*3)\n",
    "    landmarks = np.concatenate([pose_landmarks.flatten(),lefthand_landmarks.flatten(),righthand_landmarks.flatten()])\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test function\n",
    "keypointsToNumPy(results).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define key points to numpy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keypointsToNumPy(results):\n",
    "    pose_landmarks = np.array([[l.x,l.y,l.z,l.visibility] for l in results.pose_landmarks.landmark])\n",
    "    lefthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks and len(results.left_hand_landmarks.landmark)>0 else np.zeros(21*3)\n",
    "    righthand_landmarks = np.array([[l.x,l.y,l.z] for l in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks and len(results.right_hand_landmarks.landmark)>0 else np.zeros(21*3)\n",
    "    landmarks = np.concatenate([pose_landmarks.flatten(),lefthand_landmarks.flatten(),righthand_landmarks.flatten()])\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect some training data (only run it if you need to collect data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "DATA_PATH = os.path.join(\"manual_data\")\n",
    "actions = np.array([\"action_1\",\"action_2\",\"action_3\"])\n",
    "\n",
    "num_sequence = 20\n",
    "frame_per_sequence = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in actions:\n",
    "    for s in range(num_sequence):\n",
    "        # make folder\n",
    "        try:\n",
    "            os.makedirs(os.path.join(DATA_PATH,action,str(s+1)))\n",
    "        except:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lb/czvphg4j7md8_0znt29m83qc0000gn/T/ipykernel_38797/40533486.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0;31m## stop for 2 second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'Action: {action}, sequence: {s+1}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from unittest import result\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "start = False\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hoslistic:\n",
    "    for action in actions:\n",
    "        for s in range(num_sequence):\n",
    "            for f in range (frame_per_sequence):\n",
    "                success, frame = cap.read()\n",
    "                if not success: # if capture frame failed then skip the logic below and retry\n",
    "                    continue\n",
    "\n",
    "                # Copy frame\n",
    "                img = frame.copy()\n",
    "                img = cv2.cvtColor(cv2.flip(img,1),cv2.COLOR_BGR2RGB) # Set frame color to RGB to process\n",
    "                # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "                # input_img = tf.cast(img, dtype=tf.int32)\n",
    "                img.flags.writeable = False\n",
    "                # Detection section\n",
    "                results = hoslistic.process(img)\n",
    "                img.flags.writeable = True\n",
    "                # draw keypoints to the frame\n",
    "                mp_drawing.draw_landmarks(img,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(img,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(img,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "                img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) # set back to original color\n",
    "                if f == 0:\n",
    "                    ## stop for 2 second\n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(img,f'Action: {action}, sequence: {s+1}',(20,70),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2,cv2.LINE_AA,False)\n",
    "\n",
    "                keypoints = keypointsToNumPy(results)\n",
    "                npy_path = os.path.join(DATA_PATH,action,str(s+1),str(f+1))\n",
    "                # save keypoints as binary file\n",
    "                np.save(npy_path,keypoints)\n",
    "                # save frame as well\n",
    "                cv2.imwrite(npy_path+\".png\",img)\n",
    "                cv2.imshow('collect training data', img)\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "print(\"HERE\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Left_punch': 0, 'kiss': 1, 'no_action': 2, 'Right_punch': 3, 'Wakanda': 4}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.array([\"Left_punch\",\"kiss\",\"no_action\",\"Right_punch\",\"Wakanda\"])\n",
    "augmentations = [\"CW Rotate 15\",\"CCW Rotate 15\",\"Left\",\"Right\",\"Zoom In\",\"Zoom Out\"]\n",
    "label_map = {label:idx for idx,label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 6, 1662)\n"
     ]
    }
   ],
   "source": [
    "#use ch data\n",
    "num_sequence = 60\n",
    "frame_per_sequence = 30\n",
    "data,labels = [],[]\n",
    "for action in actions:\n",
    "    for s in range(num_sequence):\n",
    "        frames = []\n",
    "        for f in range(frame_per_sequence):\n",
    "            if f % 5 != 0:\n",
    "                continue\n",
    "            data_path = os.path.join(\"ch\",\"Train Data\",action,str(s),str(f))+\".npy\"\n",
    "            d = np.load(data_path)\n",
    "            # append each frame to sequence\n",
    "            # drop face\n",
    "            # d = np.concatenate([d[:33*4],d[33*4+468*3:]])\n",
    "            frames.append(d)\n",
    "        # append all frames in a sequence to data\n",
    "        data.append(frames)\n",
    "        # set the label\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "for action in actions:\n",
    "    for s in range(num_sequence):\n",
    "        frames = []\n",
    "        for f in range(frame_per_sequence):\n",
    "            if f % 5 != 0:\n",
    "                continue\n",
    "            data_path = os.path.join(\"ch\",\"Test Data\",action,str(s),str(f))+\".npy\"\n",
    "            d = np.load(data_path)\n",
    "            # append each frame to sequence\n",
    "            # d = np.concatenate([d[:33*4],d[33*4+468*3:]])\n",
    "            frames.append(d)\n",
    "        # append all frames in a sequence to data\n",
    "        data.append(frames)\n",
    "        # set the label\n",
    "        labels.append(label_map[action])\n",
    "\n",
    "# augmentation data\n",
    "for action in actions:\n",
    "    for aug in augmentations:\n",
    "        for s in range(num_sequence):\n",
    "            frames = []\n",
    "            for f in range(frame_per_sequence):\n",
    "                if f % 5 != 0:\n",
    "                    continue\n",
    "                data_path = os.path.join(\"ch\",\"Train Data Augmentation\",aug,action,str(s),str(f))+\".npy\"\n",
    "                d = np.load(data_path)\n",
    "                # append each frame to sequence\n",
    "                # drop face\n",
    "                # d = np.concatenate([d[:33*4],d[33*4+468*3:]])\n",
    "                frames.append(d)\n",
    "            # append all frames in a sequence to data\n",
    "            data.append(frames)\n",
    "            # set the label\n",
    "            labels.append(label_map[action])\n",
    "for action in actions:\n",
    "    for aug in augmentations:\n",
    "        for s in range(num_sequence):\n",
    "            frames = []\n",
    "            for f in range(frame_per_sequence):\n",
    "                if f % 5 != 0:\n",
    "                    continue\n",
    "                data_path = os.path.join(\"ch\",\"Test Data Augmentation\",aug,action,str(s),str(f))+\".npy\"\n",
    "                d = np.load(data_path)\n",
    "                # append each frame to sequence\n",
    "                # drop face\n",
    "                # d = np.concatenate([d[:33*4],d[33*4+468*3:]])\n",
    "                frames.append(d)\n",
    "            # append all frames in a sequence to data\n",
    "            data.append(frames)\n",
    "            # set the label\n",
    "            labels.append(label_map[action])\n",
    "print(np.array(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data,labels = [],[]\n",
    "# for action in actions:\n",
    "#     for s in range(num_sequence):\n",
    "#         frames = []\n",
    "#         for f in range(frame_per_sequence):\n",
    "#             data_path = os.path.join(DATA_PATH,action,str(s+1),str(f+1))+\".npy\"\n",
    "#             d = np.load(data_path)\n",
    "#             # append each frame to sequence\n",
    "#             frames.append(d)\n",
    "#         # append all frames in a sequence to data\n",
    "#         data.append(frames)\n",
    "#         # set the label\n",
    "#         labels.append(label_map[action])\n",
    "# np.array(data).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3990, 6, 1662)\n",
      "(210, 6, 1662)\n"
     ]
    }
   ],
   "source": [
    "# prepare x and y\n",
    "X = np.array(data)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,y,test_size=0.05)\n",
    "# print train and test shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(layers.LSTM(64,return_sequences = True,activation = 'relu',input_shape=(30,258)))\n",
    "# model.add(layers.LSTM(64,return_sequences = True,activation = 'relu',input_shape=(15,258)))\n",
    "model.add(layers.LSTM(64,return_sequences = True,activation = 'relu',input_shape=(6,1662)))\n",
    "model.add(layers.LSTM(128,return_sequences = True,activation = 'relu'))\n",
    "# return_sequences false as next layer is dense layer\n",
    "model.add(layers.LSTM(64,return_sequences = False,activation = 'relu'))\n",
    "model.add(layers.Dense(128,activation = 'relu'))\n",
    "model.add(layers.Dense(32,activation = 'relu'))\n",
    "model.add(layers.Dense(actions.shape[0],activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tensor board to see the accuracy\n",
    "model.compile(loss='categorical_crossentropy',metrics=['categorical_accuracy'],optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 10s 22ms/step - loss: 1.0547 - categorical_accuracy: 0.4960\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.3932 - categorical_accuracy: 0.8461\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 0.1105 - categorical_accuracy: 0.9647\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0663 - categorical_accuracy: 0.9779\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0541 - categorical_accuracy: 0.9845\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0847 - categorical_accuracy: 0.9727\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0316 - categorical_accuracy: 0.9907\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0151 - categorical_accuracy: 0.9955\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0185 - categorical_accuracy: 0.9937\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0068 - categorical_accuracy: 0.9982\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0847 - categorical_accuracy: 0.9779\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.1241 - categorical_accuracy: 0.9677\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0110 - categorical_accuracy: 0.9970\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0137 - categorical_accuracy: 0.9962\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0151 - categorical_accuracy: 0.9957\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0107 - categorical_accuracy: 0.9975\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0136 - categorical_accuracy: 0.9957\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 3s 24ms/step - loss: 0.0105 - categorical_accuracy: 0.9960\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0088 - categorical_accuracy: 0.9975\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0021 - categorical_accuracy: 0.9995\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.0624 - categorical_accuracy: 0.9769\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0093 - categorical_accuracy: 0.9975\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0013 - categorical_accuracy: 0.9997\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.0017 - categorical_accuracy: 0.9995\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 3s 23ms/step - loss: 5.7285e-04 - categorical_accuracy: 0.9997\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 2.1989e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.0447e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 1.9976e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 3s 22ms/step - loss: 1.1730e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 1.4927e-04 - categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(\"logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "history = model.fit(X_train,Y_train,epochs=30,callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_15 (LSTM)              (None, 6, 64)             442112    \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 6, 128)            98816     \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 602,949\n",
      "Trainable params: 602,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 8ms/step - loss: 0.0502 - categorical_accuracy: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05019490793347359, 0.9952380657196045]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 9ms/step\n",
      "[2, 3, 1, 3, 0, 3, 0, 4, 3, 4, 3, 0, 1, 0, 1, 4, 4, 1, 1, 4, 1, 1, 3, 1, 4, 2, 3, 0, 3, 0, 3, 3, 3, 0, 2, 0, 0, 3, 1, 1, 4, 3, 0, 4, 3, 1, 4, 2, 0, 1, 4, 3, 0, 0, 2, 0, 0, 4, 3, 3, 1, 4, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 3, 2, 2, 0, 2, 2, 3, 3, 4, 0, 3, 0, 4, 0, 0, 2, 2, 2, 2, 0, 3, 4, 3, 4, 2, 4, 2, 4, 1, 3, 1, 4, 0, 1, 2, 1, 0, 3, 4, 2, 3, 2, 4, 1, 3, 2, 0, 0, 2, 2, 0, 2, 4, 1, 2, 3, 3, 0, 3, 4, 3, 3, 2, 3, 3, 4, 3, 0, 4, 1, 2, 1, 2, 2, 2, 3, 3, 2, 3, 0, 3, 3, 0, 0, 0, 0, 2, 4, 0, 1, 2, 3, 0, 3, 2, 0, 0, 2, 4, 0, 4, 2, 2, 2, 3, 4, 4, 0, 0, 3, 0, 3, 4, 0, 1, 0, 4, 4, 2, 2, 2, 2, 1, 1, 1, 2, 0, 4, 2, 1, 1, 3, 4, 0, 4, 0, 2]\n",
      "[2, 3, 1, 3, 0, 3, 0, 4, 3, 4, 3, 0, 0, 0, 1, 4, 4, 1, 1, 4, 1, 1, 3, 1, 4, 2, 3, 0, 3, 0, 3, 3, 3, 0, 2, 0, 0, 3, 1, 1, 4, 3, 0, 4, 3, 1, 4, 2, 0, 1, 4, 3, 0, 0, 2, 0, 0, 4, 3, 3, 1, 4, 1, 1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 3, 2, 2, 0, 2, 2, 3, 3, 4, 0, 3, 0, 4, 0, 0, 2, 2, 2, 2, 0, 3, 4, 3, 4, 2, 4, 2, 4, 1, 3, 1, 4, 0, 1, 2, 1, 0, 3, 4, 2, 3, 2, 4, 1, 3, 2, 0, 0, 2, 2, 0, 2, 4, 1, 2, 3, 3, 0, 3, 4, 3, 3, 2, 3, 3, 4, 3, 0, 4, 1, 2, 1, 2, 2, 2, 3, 3, 2, 3, 0, 3, 3, 0, 0, 0, 0, 2, 4, 0, 1, 2, 3, 0, 3, 2, 0, 0, 2, 4, 0, 4, 2, 2, 2, 3, 4, 4, 0, 0, 3, 0, 3, 4, 0, 1, 0, 4, 4, 2, 2, 2, 2, 1, 1, 1, 2, 0, 4, 2, 1, 1, 3, 4, 0, 4, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "# get the index with max value (label)\n",
    "yTrue = np.argmax(Y_test,axis=1).tolist()\n",
    "yhat = np.argmax(yhat,axis=1).tolist()\n",
    "print(yTrue)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0,  0,  0],\n",
       "       [ 1, 33,  0,  0,  0],\n",
       "       [ 0,  0, 44,  0,  0],\n",
       "       [ 0,  0,  0, 46,  0],\n",
       "       [ 0,  0,  0,  0, 36]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yTrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952380952380953"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(yTrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFXCAYAAACV2fZmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABA8UlEQVR4nO3deVzUBf4/8NfcMAz3pSigoHihIlhmhVeRebUqFWpfdc36Vlv73e1cazu8Uju2dr99y93ctp/fTs3akq228iiMym9MgoIKHoiixCHnzMBcn8/vj4ERcnBAgc8w83o+Hjzmc81n3rwd58XnHJkoiiKIiIioz8mlLoCIiMhXMYSJiIgkwhAmIiKSCEOYiIhIIgxhIiIiiTCEiYiIJMIQJpJIeXk5JkyYIHUZbo0YMQK1tbVSl0HklRjCREREEmEIE3mgpqYmPPLII5g7dy7mzZuH559/HjabDQDw3//935g3bx4WLlyIlStXoqqq6pLT268zNTUV1dXVzmm33XYbvvnmG5SWlmLFihW4/fbbMX36dNx3330wm80dnv/RRx/hnnvucTlusViwYcMGLFiwALfccgtWrVoFg8HQK70h8iYMYSIPtH79eoSEhCA7OxsffvghiouL8Y9//AMVFRXYunUrPvzwQ3z00Ue47rrrcPDgwU6ntxcYGIiMjAzs3LkTAHDixAnU1NQgPT0d27dvx/z587F9+3Z8+eWXKC8vx9dff93lel9//XUoFAp89NFH2LlzJ6KiovDiiy/2ZEuIvJJS6gKI6GI5OTl47733IJPJoFarsWjRImzduhV33XUXRo4ciQULFmDKlCmYMmUKJk+eDEEQXE7/pdtuuw1r1qzBypUr8eGHHyIzMxNyuRyPPvoocnNzsWXLFpw6dQpVVVUwmUxdrvfrr79GU1MTvvvuOwCA1WpFeHh4j/WDyFsxhIk8kCAIkMlkHcZtNhvkcjnefvttHDp0CN9//z02bNiA9PR0PPbYY51Ob2/ixImw2Ww4ePAg/vWvf2Hbtm0AgIceegh2ux2zZs3CtGnTUFFRgV/eVl4mk3WYZrVaO9T3xBNPYOrUqQAAo9F40e5sIroYd0cTeaDrr78eb7/9NkRRhMViwfbt23Httdfi6NGjmDt3LhITE3HPPffg17/+NQ4dOtTpdFduu+02rFu3DiNGjMDAgQMBAN9++y3uv/9+zJ49GwBQUFAAu93e4XlhYWE4duwYzGYzrFYrvvjiiw71vvPOO7BYLBAEAU899RReeumlXuoOkffgljCRhEwm00WXKb3//vt48sknsX79esybNw9WqxXp6em49957oVarMWvWLGRmZkKr1cLPzw9PPvkkRo4c6XK6K/Pnz8dLL73UISQffPBB3H///dBqtdDpdLjqqqtw+vTpDs+77rrrcNVVV2HWrFmIjIzEpEmTUFxcDAD4zW9+g+eeew4LFiyA3W7HqFGjsGrVqh7uFpH3kfGrDImIiKTB3dFEREQSYQgTERFJpEshXFBQgKVLl140/c0338ScOXOwdOlSLF26FCdPnuzxAomIiLyV2xOztmzZgp07d8Lf3/+ieUVFRXjuueeQnJzcK8URERF5M7chHBcXh1deeeWi6w0BRwi//vrrqK6uxrRp0zrc0s4VQRBgNBqhUqk6XANJRETkrURRhNVqRUBAAOTyjjug3YbwzJkzUV5e7nLenDlzsGTJEuh0OjzwwAPYu3cvpk+f3um6jEYjSkpKulk+ERFR/5eUlITAwMAO0y77OmFRFLF8+XLnCqdOnYrDhw9fMoRVKpWzELVafbkv3UFhYSF3h7vAvrjGvrjGvrjGvrjGvrjWWV8sFgtKSkqcGdjeZYewwWDA3Llz8dlnn0Gr1WL//v3IzMy85HPadkGr1WpoNJrLfemL9OS6vAn74hr74hr74hr74hr74tql+uLqMGy3Qzg7OxsmkwlZWVl48MEHsWzZMqjVakyePNl531giIiJyr0shPHjwYGzfvh0AMG/ePOf0+fPnY/78+b1SGBERkbfjzTqIiIgkwhAmIiKSCEOYiIhIIgxhIiIiiTCEiYio3zKbzfjggw+6tOxHH32E3bt3dzr/9ddfx8GDB3uqtC657OuEiYiIpFZdXY0PPvgAt912m9tlFy5ceMn5//mf/9lTZXUZQ5iIiK7YY9l67Cgo69F13jo+Hs/PS7vkMn/9619x/PhxjBw5Etdeey1MJhOeffZZfPzxxygsLITRaERiYiI2btyIV155BREREUhISMCWLVugUqlQXl6O2bNn47777sOqVaswe/Zs1NTU4JtvvkFLSwtOnz6Nu+++GwsXLsTBgwexZs0aBAQEIDw8HBqNBps2bbqi35EhTERE/da9996LkpISpKeno6GhAU8++SQMBgOCgoLw5ptvQhAEzJkzB5WVlR2ed+7cOezcuRMWiwXp6em47777Osw3GAx44403cOrUKdx7771YuHAhnnnmGTz//PMYPnw4Xn755YvWeTkYwkREdMWen5fmdqu1tw0dOhSA49aRtbW1eOihh6DVamEymWC1Wjssm5SUBKVSCaVSCT8/v4vWNXLkSADAwIEDYbFYAABVVVUYPnw4ACAtLQ2fffbZFdfMECYion5LLpdDEATnMADk5OSgoqICf/7zn1FbW4uvvvoKoih2eJ67r9N1NX/AgAE4fvw4hg0bhoKCgh6pnyFMRET9Vnh4OKxWK1paWpzTxo0bh9deew2333471Go1YmNjUVVVdcWv9cwzz+CJJ56AVquFSqVCdHT0Fa+TIUxERP2WRqPBJ5980mFaZGQkPvzww4uWTUu7sLt80qRJzuHc3FwAcHmSlUajwZ49ewAAhw4dwl//+leEhYXh5ZdfdvnVhN3FECYiIuqC8PBw3HnnndBqtQgMDLziM6MBhjAREVGX3Hzzzbj55pt7dJ28YxYREZFEGMJEREQSYQgTERFJhCFMREQkEYYwERGRRBjCREREEmEIExERSYQhTEREJBGGMBERkUQYwkRERBJhCBMREUmEIUxERCQRhjAREZFEGMJEREQSYQgTERFJhCFMREQkEYYwERGRRBjCREREEun3IWwTRKlLICIiuiz9OoRzS6swZfsR5JyolLoUIiKibuvXIWwXRNgE4OPC01KXQkRE1G1dCuGCggIsXbr0oul79uxBZmYmsrKysH379h4vzp2r4yKgksuw72RVn782ERHRlVK6W2DLli3YuXMn/P39O0y3Wq3YuHEjduzYAX9/fyxevBjTp09HZGRkrxX7S34qBcaE+yP/bB0ami0I9lf32WsTERFdKbdbwnFxcXjllVcumn7ixAnExcUhODgYarUaaWlpyMvL65UiL2VClBaCKOK7U9V9/tpERERXwm0Iz5w5E0rlxRvMBoMBgYGBzvGAgAAYDIaera4LJkRpAQD7TvLkLCIi6l/c7o7ujE6ng9FodI4bjcYOoXwphYWFl/uyFxkb4Q+FDPj3oZPIHMDLldrT6/VSl+CR2BfX2BfX2BfX2BfXutuXyw7hxMRElJWVob6+HlqtFnl5eVi5cmWXnpucnAyNRnO5L92BXq9H6uBw5J+rw+hx4+Gvuuxfyavo9XqkpaVJXYbHYV9cY19cY19cY19c66wvZrO5043PbidWdnY2TCYTsrKysGrVKqxcuRKiKCIzMxPR0dHdr7oHXJ8QhR/PnMf+shpMGzZAkhqIiIi6q0shPHjwYOclSPPmzXNOnzFjBmbMmNE7lXVDekI0Xv7mCPadrGIIExFRv9Gvb9bR5vqhUQB4chYREfUvXhHC4QEaJA8IwXenqmGx2aUuh4iIqEu8IoQBID0hCs1WO346Wyt1KURERF3iRSHsOCls3wnewpKIiPoHLwrh1uPCpTwuTERE/YPXhHBMsBbDIgLx7ckq2AVB6nKIiIjc8poQBhxnSTe0WFH4c73UpRAREbnlVSHM48JERNSfeFUIT0l0HBfO4fXCRETUD3hVCA8N02FQsBb7TlZBFPllDkRE5Nm8KoRlMhnSE6JQZWhBSXWj1OUQERFdkleFMNDuuPBJHhcmIiLP5nUhPKXtemGGMBEReTivC+FR0cEI12r4ZQ5EROTxvC6EZTIZrk+IQlmdEWW1BqnLISIi6pTXhTDQbpd0KXdJExGR5/LKEL5wchZ3SRMRkefyyhAeHxOKQI2Kd84iIiKP5pUhrFTIce3QSBRXN6KyqVnqcoiIiFzyyhAGLhwX/pbHhYmIyEN5bQjzph1EROTpvDaEJ8aGQ6OUY98JnpxFRESeyWtDWKNU4Jr4SBRU1KG+2SJ1OURERBfx2hAGgPSEKIgikMvjwkRE5IG8PIR5XJiIiDyXV4fw5PgIKOUy3rSDiIg8kleHcIBGhbTB4cg7cx4mi03qcoiIiDrw6hAGHMeFbYKIH8qqpS6FiIioA68P4ev5/cJEROShvD+Eh0ZBJuOXORARkefx+hAO1WowdkAovj9VA4vNLnU5RERETl4fwoDjuHCLzY68M+elLoWIiMjJN0I4kdcLExGR5/GNEB7qODkrh8eFiYjIg/hECA8I8kdSZBC+O1UNuyBIXQ4REREAHwlhwHFcuLHFioPn6qUuhYiICEAXQlgQBDz99NPIysrC0qVLUVZW1mH+m2++iTlz5mDp0qVYunQpTp482WvFXokL1wtzlzQREXkGpbsFdu3aBYvFgm3btiE/Px+bNm3C5s2bnfOLiorw3HPPITk5uVcLvVJTWr/MIedkFf5ryiiJqyEiIupCCOv1eqSnpwMAUlJSUFhY2GF+UVERXn/9dVRXV2PatGm45557eqfSKxQfGoDYEC32nayEKIqQyWRSl0RERD7ObQgbDAbodDrnuEKhgM1mg1LpeOqcOXOwZMkS6HQ6PPDAA9i7dy+mT59+yXX+MsivlF6v79JyY0JU+PcpEz7c+z2GBmt6tAZP1NW++Br2xTX2xTX2xTX2xbXu9sVtCOt0OhiNRue4IAjOABZFEcuXL0dgYCAAYOrUqTh8+LDbEE5OToZG0zMhqNfrkZaW1qVlf2UJxL9P7cd5/wjcmpbUI6/vqbrTF1/CvrjGvrjGvrjGvrjWWV/MZnOnG59uT8xKTU1FTk4OACA/Px9JSRfCy2AwYO7cuTAajRBFEfv37/foY8Ntx4W/5U07iIjIA7jdEs7IyEBubi4WLVoEURSxYcMGZGdnw2QyISsrCw8++CCWLVsGtVqNyZMnY+rUqX1R92UZERWESJ0GOSd4XJiIiKTnNoTlcjnWrl3bYVpiYqJzeP78+Zg/f36PF9YbZDIZrh8ajX8eOo2yOiOGhOncP4mIiKiX+MzNOtpMSeAtLImIyDP4XAintx4X3neCx4WJiEhaPhfC42JCEOSn4p2ziIhIcj4Xwgq5HNcNjcKxmiZUNJqkLoeIiHyYz4UwcOG48M6icokrISIiX+aTIbwkdSj8VQqs+/IgDGar1OUQEZGP8skQHhwSgEemjUFFYzNe2FskdTlEROSjfDKEAeDR6aMRE+SPP319GGfqjO6fQERE1MN8NoQDNCqsnz0BzVY7nvjsgNTlEBGRD/LZEAaApWkJSB0chnd/KsX/na6RuhwiIvIxPh3CcrkMf7plIgDg4U/yIIqixBUREZEv8ekQBoApidFYMDYO352qxgcFZVKXQ0REPsTnQxgAnpubCpVCjsc//QktVrvU5RARkY9gCANIjAjEb68fiVO1Rvwl54jU5RARkY9gCLf6Y8ZYRARosHF3ISqbmqUuh4iIfABDuFWIvxqrZ45Hk9mKZ/5dIHU5RETkAxjC7dx9zXCMig7GG/uP41BFndTlEBGRl2MIt6NUyPHCvDQIoshLloiIqNcxhH9h1qhBuGlEDHYf+xmfHjkrdTlEROTFGMIuvHhLGhRyGR7bqYfVLkhdDhEReSmGsAtjBoTg7muGo7i6EX/7rkTqcoiIyEsxhDuxeuZ4BPmpsObLAtSZzFKXQ0REXogh3IlInR/+eONY1JosWPfVQanLISIiL8QQvoTfpo9EQrgOr35bjJLqRqnLISIiL8MQvgSNUoFNc1NhE0T8IVsvdTlERORlGMJuLBwbh/SEKOwsKsfe4z9LXQ4REXkRhrAbMpkML7b7zmG7wEuWiIioZzCEu2BibDiWTkxAwbk6/L8fT0hdDvURQRBRcK4Wr+w7gj9k61FWa5C6JCLyMkqpC+gvnp09ATsKyvDU5/lIGxyO8TGhkMlkUpdFPcguCCg4V4ecE5X4+kQlvj1Zhbpmi3P+6z8cw/8svBp3pCVIWCUReROGcBcNCtbiDzOSsfqLAqS99CmiA/2QkRSDjBEDcVPSQEQF+ktdInWTzS7gwNlafHOiEt+cqERuaRUaWqzO+UPDdLglORZTEqJhttvxWLYey97NxWdHzuLVzEkI8VdLWD0ReQOGcDf88caxSIoMwmdHzuKrknN4W38Sb+tPAgAmDApDRtJA3DQyBtcNiYRaqZCszharHWcNFqSKIrfW2xEEEYdqTNi1uxDfnKzEd6XVaDJfCN1hEYHIHBePqcOiMTUhGrGhAR2ef+PwgVj27rd4/8ApfHeqGlsXX4cpidF9/WsQkRdhCHeDXC5D1oQhyJowBKIo4mBFHb48WoEvi8/h29IqHDhbi+f3FiFArcS0YdG4KSkGN42MwfCIwF4Lw4ZmC/LP1SH/bC0OnK1F/tlaHKlsgE0QEbevApnj4nDb+HhcHRfhs4FsFwR8ePA0Nuw6hEMV9QBOAQBGRgVhSuIQTEmIxpTEaAwK1l5yPYkRgfjm/pnYsOsQ1u86hBmbv8QfZiTjmZvGSfpHFxH1XwzhyySTyTA+JgzjY8Lw6IwxMJqt+OZkFb4sPocvj57Dp4fP4tPDjm9hGhIWgBnDBiI2RIuIAD+EB2gQHqBBRIAG4VoNInQa+Kvc/1NUNJpw4GzHwD15vuPJQlq1AlfFRkBjb8FPNS14+ZsjePmbI4gLDUDmuDjcOj4ek3wkkG12Ae8dOIVNuw/haFUj5DIZbooPwoop4zElIRoDgrp/CEGpkOPpmeORMSIGy979Fpt2F+Kr4nN4647rMSIquBd+C5JKi9WO0gYzJggi5HLv//9C0mAI95AAjQqzRw3C7FGDAABltQZ8WeLYSt5dUoF//N/xSz7fX6VARIAGEQF+CNOqnWHtp1SgqLIe+WdrUdnU0uE54VoNbhg+ABMGhSFlUBgmDArD8MhAKORy6PV6JI9PwZfF57Cj4DR2Fp1xBnJsiBaZ4+KdgextHzAWmx3/m3cSz+0pxMnzBijlMtx59TD84YYxaCg7hrSUIVf8GpOHROKnh+bidx//iK0/nsDElz/Fi7dMxH9eM9wn/sDxVqIo4scz57H1xxN4/8Ap1DdbELPvHBaOi8Nt44fg2iGRXvf/haTFEO4l8WE63H3NcNx9zXDY7AKOVDWgqqkFNUYzak1m1BjNOG8yo8bQcdqxmkYYzLaL1xcagF8lx7YGbigmDArDoGDtJT/wNUoF5o2JxbwxsTDb7PiqpAI7Csqws/AM/pxzBH/OOYLBwVpkjnd8wPT3QG6x2vHm/x3H83uLcLrOCLVCjnuvTcJj08cgPkwHANCX9dzrBfqp8I9F12L2qEG494Mf8Jsd+/H5kbPYcvtkROr8eu6FqNf93NiMt/UnsfXHEzhc2QAAiAnyR1pkEH6qbsH/fFuM//m2GDFB/ljYukfpuiFR/fr/C3kGhnAfUCrkGDswFBjYteVbrHacN5lx3miG0WLDiKgghGk1V1SDRqnA3NGDMXf0YJhtduxqDeRPCs/gLzlH8ZecoxgcrMWvkmORFBmEmGAtYoL9MShIiwFB/lApPPeScqPZii0/HMOLXx9GRWMz/FUK/G7KSDwybQxi3Bzn7Qm3jo/HNfERWPHed8guKsf4F7PxRta1mNW6V4Q8k8VmR/bhcmz98QT+ffQc7IIItUKO28bHY/lVichIGoiC/AMYlzIBe479jA8KTuGTwjPOQB4Y5I+FY1sDeWgkFHLP/T9CnsttCAuCgNWrV6O4uBhqtRrr169HfHy8c/6ePXvw6quvQqlUIjMzE7fffnuvFuwL/FQKDArWuj1R6HJplArMGT0Yc0YPhsVmx65jP+OD/FPYWVSOV3OLL1peJgOidH6ICXIEc0yQo7aBQf4Y1BrW0Tp/CKIIi12AxS7AahdgsQmwCo5Hi90Oq13s8GixCxBFIMRfjTCtGuFax7HyMK2mS6Hf2GLB5twSvJxzGNUGM3QaJR6bPgYPTh3V55eMDQ4JwBf33Ig/5xzBE58dwNy/78H9143Ac/NSu3S8vytEUYRdECGIIgQRrY8Xxu2CCABQK+TQKOVQKeTcNe7CgfJabM07gXf1pTjf+jWlE2PD8eurEpE1YchFf/CqFHLMHBmDmSNjsPlWAXuO/YwdBWX4uPA0Xs0txqu5xRgQeGEL+XoGMnWD20+HXbt2wWKxYNu2bcjPz8emTZuwefNmAIDVasXGjRuxY8cO+Pv7Y/HixZg+fToiIyN7vXDqGWqlwnks22KzI+/MeZQ3mFDR2IyzDSacbTd8tKoBB87W9kldgRoVwgMcwRyq1bQLaMe0GqMZr+UWo67ZgmA/FZ7KGIffpo9EeMCV7TG4EnK5DA9NG40ZwwfgP975Fq/mFuOzI2cRHxoAmyDCahdgE4R2wyJsgtBh2GYXYW19bB+wgiheVk2OQFZAo/zFY7vpaqUCzYYmaPPqOtTXVlf7xw7DggBBFKGUy6FSyKCSO4Lf+dM2vd24UuGYppTLoZDLoJDJoJDLIG99VMjaDbeNt1tOKZdBq1YiQK2Ev8rxGKBWQqtWOIcD1EpoVUoEaBzDaoUcNUYz3v2pFFt/PIGCc3UAHH9YPjR1NJZflYDkgaFd6mf7QH7t1knYe7w1kA+dwWu5xXitNZBnjYpBdKA/AjVKBGpUCFCrEOjnGHb8tA77OcY9eU8T9S63IazX65Geng4ASElJQWFhoXPeiRMnEBcXh+Bgx1mhaWlpyMvLw6xZs3qpXOpNaqUC1w6N6nS+KIpoaLHiXGs4n2tsxrnWxypDC5RyGdStH7jtH9VKxwdwh0eFAiqFDDLI0NBiwfnWY+S1JgtqncNmHKlqgMlid1lPuFaDdbNScP91IxDsQTfOSBkUhh8fnI0/ZP+Ev35fgtJaA+QymTN8lHJZa3C1Ditk8FMqoFRcmKeUXwgnxw8uDMtdTJMBCrkcIkRYbALMNjusdgHm1mGzvfXRJqCxxeqcbrG3vxf6hTPtVYoLwdq+VpVCDq36wrBcJnP+IWFt/QPCaLE5A9sqtE63S3fPdYVcBrH1DxmlXIb5Y2OxfGIiZo0adEXhp1LIcdOIGNw0IgavZk7C18d/xgetgfzm/3Xv9rYapRyBGhW06gsfyaIoQhQBsf24cxgQ4ZjfRvaL94NcJvvFNMd0Wfv5cCwDADLAueek/TS0Tpe1ex2j0Qjdt1UdfgdXO10uPMu9C79dz+pODW0GBvvj7Tuuh6YPLj10G8IGgwE6nc45rlAoYLPZoFQqYTAYEBgY6JwXEBAAg8H9/XXbB3lP0Ov5NYOu9GZfwgCEyYHkUAChCgABl1haaP3phK71B6rWn47rMtsFNJrtaLDY0WB2/NhFEdfFBEKrsuD44UPdqr2v3i/L4xX4j9iRzg9CTySKIqyCCJsAKOSAsnWLszdexy7CscUvirALjlC0i455ggjYO+xmd4yLwIV5guOxxS6g2SaixSag2SagxSagxS6iuXXc3Dr/wjwBcpkM0wYH4uYhwQj1UwLmKhzMr3JbN9D190sYgHsS1Vg5NAGnGs0wWgWYrAKMNgEmq73dsADTRY+O+S0WS4d1OoKx9RGtgdI+NOWORxGtwSwCotDaazh62TZPaA1uQWxb3jGM1uej/TAuhGL7PwQu/HsCqDNfGHfRD1ehKoquw/rC79uz773LDfbIGhV++FEPnbr7Idzdzxe3IazT6WA0Gp3jgiBAqVS6nGc0GjuEcmeSk5Oh0fTMbkO9Xo+0tLQeWZc3YV9cY19cY19cu9y+TOqFWjwJ3y+uddYXs9nc6can230xqampyMnJAQDk5+cjKSnJOS8xMRFlZWWor6+HxWJBXl4eJkyYcLn1ExER+RS3W8IZGRnIzc3FokWLIIoiNmzYgOzsbJhMJmRlZWHVqlVYuXIlRFFEZmYmoqN5L10iIqKucBvCcrkca9eu7TAtMTHROTxjxgzMmDGjSy8mtp5FYPnFcY8rZTab3S/kg9gX19gX19gX19gX19gX11z1pS3zRBdXOchEV1N7SVNTE0pKSvrq5YiIiDxGUlLSRedN9WkIC4IAo9EIlUrFmwgQEZFPEEURVqsVAQEBkP/iRi59GsJERER0AW/TQkREJBGGMBERkUQYwkRERBJhCBMREUmEIUxERCQRhjAREZFEGMJEREQSYQgTERFJhCFMREQkEYYwERGRRBjCRB7IarXi+uuvx1133SV1KUTUixjCRB7oq6++wsiRI1FYWIgTJ05IXQ4R9RKGMJEHeu+993DDDTdg9uzZ2Lp1q3P6jh07MGfOHMybNw/Lli1DRUVFp9P379+PuXPnOp/bfvyVV17BypUrMW/ePDzyyCOoqanBb37zG2RlZWHGjBlYunQpzp8/DwAoLS3F0qVLnev/7LPPoNfrMW3aNAiCAABobm7G5MmTUVtb21ctIvIKDGEiD3P8+HEcOHAAN998M+bPn49PPvkEdXV1OHr0KF588UX8/e9/R3Z2NmbMmIHNmzd3Ot2ds2fP4p///CdefPFFfPrpp0hJScG2bduwe/du+Pn54ZNPPgEAPPTQQ7j55pvx6aef4vXXX8dLL72EESNGIDg4GPv27QMAfPrpp5g8eTLCwsJ6tTdE3kYpdQFE1NF7772H6dOnIzQ0FKGhoRg8eDC2b98OtVqN66+/HgMHDgQA/PrXvwYAvPnmmy6n79+//5Kvk5KSAqXS8RGwfPly5OXl4c0338SpU6dw7NgxjB8/HvX19Th69Chuu+02AMDAgQOxa9cuAMAdd9yB7du3Y+rUqdi2bRsee+yxnm4FkddjCBN5EJPJhE8++QRqtRozZswAABgMBrz99tu46667IJPJnMu2tLTg7NmzUCgULqfLZDK0/7pwq9Xa4bW0Wq1z+IUXXsDBgweRmZmJSZMmwWazQRRFZ0i3X//JkycRExODefPm4aWXXsIPP/wAk8mEq666qmebQeQDuDuayINkZ2cjJCQE+/btw549e7Bnzx7s2rULJpMJTU1N+P7771FVVQUAeP/99/HCCy9g0qRJLqeHhYXh3LlzOH/+PERRxKefftrp63777bdYvnw55s+fj/DwcHz33Xew2+3Q6XQYM2YMPv74YwBARUUFFi9ejKamJvj7++OWW27BE088gUWLFvV6b4i8EbeEiTzIe++9hxUrVkChUDinBQUFYenSpdi7dy8effRR52VLkZGR2LBhA6KjozudvmjRImRmZiIyMhLTpk3DoUOHXL7u/fffj+effx5/+ctfoFKpkJqaitOnTwMA/vSnP2HNmjV46623IJPJ8OyzzyIyMhIAsHDhQmzfvh3z58/vxa4QeS+Z2H5/FRFRF4miiC1btuDs2bNYs2aN1OUQ9UvcEiaiy3LDDTcgKioKr732mtSlEPVb3BImIiKSCE/MIiIikghDmIiISCJ9ekxYEAQYjUaoVKoO1x0SERF5K1EUYbVaERAQALm847Zvn4aw0WhESUlJX74kERGRR0hKSkJgYGCHaX0awiqVylmIWq3ukXUWFhYiOTm5R9blTdgX19gX19gX19gX19gX1zrri8ViQUlJiTMD2+vTEG7bBa1Wq6HRaHpsvT25Lm/CvrjGvrjGvrjGvrjGvrh2qb64OgzbpROzCgoKsHTp0oum79mzB5mZmcjKysL27du7USYRERG53RLesmULdu7cCX9//w7TrVYrNm7ciB07dsDf3x+LFy/G9OnTnbezIyIioktzG8JxcXF45ZVXLvqashMnTiAuLg7BwcEAgLS0NOTl5WHWrFm9Uyn5LFEU0dhiRbWxBTVGM2qMZphtdkwfNgBhWs/eJWY0WyECUMhlUMrlUMhkkMuluzJAEESY7Xa0WO1osbU9CjhW1wJdVQP8lAr4qRTOR7VC3udXMrTVaLEJMNvsMNsEWOwXhputNjRb7Wi22R2PreMt7YYv/DjG1Qo5MsfH4+YRMVAqevfKTKtdwOHKehjMNhgtNpgsNpisdpgsNjRbbTBZ7DBZ2+Y5htuWMVvtAACZzLHrUobWRxmcw3IZIEPHaTIZIIqO/ysiWochQvjlNOew4x5NbcuJIiC4XK5tPWLrsGOe0WRCQM7PvdpHKQ0M0mLbsinwUyncL3yF3IbwzJkzUV5eftF0g8HQ4SyvgIAAGAyGLr1oYWFhN0p0T6/X9+j6vEVP9qXFJqDObENdix31rY8Xxu1otNihksugksugUcigVsihVrQNy6CWyzsMq1uHFTIZGi2Oddab7Rd+WtqP22B3cV83pRy4NiYQNw8JxvUxOvgpu/bh2hfvl6O1zfjbwWrknnP9f0IhgyOQZY6AVsgAuczRj7ZhuQyOD1znsAxyOD6gnfPhGJa1LgsAVrsIiyDCbBdhsQuw2EXHjyDCKlziBnmfn3Q5WS2XOf+9NK3/rm3/zsp2f1A4Pshbh9HuQ9sxAQI6frhbW+ux2EVYBcE57Orfuif8b95JRPkrMS8xBLckhmBgQNdODu3K+0UURRSdb8bnpxrwVVkj6s32Ky1XMo5gdzwCre+v1mnt56PRLEl9faGqwYD9ej10lxHC3f18uewTs3Q6HYxGo3PcaDRedOp1Z5KTk3vsoL5er0daWlqPrMubdLcvVruAr4//jL3Hf8bPTS2oNrSgxtiCKkMLqg1mGC22XqzWtVB/NSJ0/kiK9kN4gAYRARpE6vwQEaCB2WbHjoLTyCmvQ055EwI1KiwcF4clqUMxfVg0FHLXgdzb75fCijqs/uIg/nnI8Q1EE2PDEaXzg10UYbMLEEQRdkGETWh7FGAXRMf8X0wTRMeWjL31OY7x1mmC0G68bZoIEaJjK7Z1S1brp0aoUt5hC1fTtqWrVECjlMNPpUDd+RqEhEW02zp2PLZtfXaYbrOjvsXxaLYJrR/YMucfDBc+xFu31mRtH+QXtt7kMhk0SgXUajl0CrljWCmHRuGoSa10bIVrlK3zWpfRKOXwVyngr1K2Pjp+r/bjHYcd4xWNzfjH/uN496dSvFFYg38U1eCmETG4a9JwzBszGKpOto7dvV9O1DTh3Z9K8Y7+JI7VNAEAInUa3Dl+KKIC/aBVKRCgVsJfrYRWpYRWrWh9VEKrUjgfA9SOaRql40P/oi1RoeN4+63Stukdtoxx4Y+zjlvTsouWc/77dGOPBz93XeusL2azudONz8sO4cTERJSVlaG+vh5arRZ5eXlYuXLl5a6OJGA0W/FFcQU+LjyNTw+fRX2zpcN8tUKOSJ0fhkcEIlLnh0idH6J0fojUaRAR0DbsGA/118AmCI4Pbrvwi92dHT/AW6yOXY0tNjusdgGhWo1znRGtYRum1XT6wdjmjxnjUFhRh3d/KsV7B05h648nsPXHExgY5I+slCFYkjoUqYPD+mR3akl1I9Z8UYBt+acgisA18RFYc3MKbhg+oF/cmMbbP1QHBWsxMTYcL8xLxfaCMrzxw3F8cfQcvjh6DtGBflg+MRErrxmGYRFBbtdVY2jBBwVleEdfiu/LqgEA/ioFFk0YgjvSEpCRNNDte5eoTbdDODs7GyaTCVlZWVi1ahVWrlwJURSRmZmJ6Ojo3qjRawmCiGpjC87Um3Cm3ogzdUbncHm9Cafrjag1mTEqOhgTY8MxMTYcV8VGYHR08GUf1zpvNCO7qBwfF57GV8UVaLE5dpvFhmjxH2lDMXf0YAwN1yEywA9Bfp5/Z7PkgaHYMCcU62dNQO6pKrz7Uyk+yC/Dn3OO4M85RzAiMghL0oZiSepQJIR3bU9Nd5Seb8K6rw7hrbyTEEQREwaFYc3N4zF71CCP750vCtCosOLqYVhx9TAUVtThjf3H8VbeSTy/twjP7y3C9GHRWDlpOBaMjetwPLDZasO/Dp/FO/qT+PzIWdgEEXKZDDcmDcQdaUOxIDkOgX4XXwNK5E6ffotS2ya5L+2OtgsCDp6rx49nanC6NWTL64043Rq0Frvg8nlKuQyDgrUI9lPjaFVDh+W0agUmxIRhYlw40gaH46q4CAwLD+xwwk/7vpypM+KTwjP4uPA0ck5Wwd564G5UdDDmJ8di/tg4pPXRFmNfsNjs+PfRc3j3p1JkF5U7/9C4Jj4C10UocOv1qRgTHYwAzeV/aJbXG/HsrkP4x/7jsAkixgwIxuqZKVgwNrZf9tHT/x/1pharHR8dOo2//3AM35yoBACEadVYOjEBg2HE4RY1Pjx4Go0tVgBASkwo7khLwKIJQxATrJWydMn48vvlUtztjnaVffw+4R5mMFuxv6wG352qxrelVdhfVoMms/Wi5QYE+mN8TCgGhwQgLlSL2JAADA4JQGyIFnEhAYgO9HMe17TY7DhUUY+88vPIO30eeWfO44fTNcg9Ve1cX7Cfyrm1PDE2Asbzzfhy1yF8XHgGeWfOO5ebFBeB+WNj8avkWIyICu79hkhArVTgluRY3JIci8YWC/556Aze/akUe479jB/KRPxJ/zlkMmBYeCDGxoRi3MBQjB0YgnExoRgSqrvk2cs/NzZj055CvP59Ccw2AUmRQXj6pnG4PSW+0+PQ5Nn8VAosSXXsLSmpbsQbPxzD1rwT+EvOUecysSFa3HdtEpakDkXywFAJqyVvwxC+QhWNJuSWViO3tAq5pVXIP1fn3NIEgJFRQbhuaDyuiY9EYkQgYkO0GBSsdZ6A0RVqpQJpseFIiw3HPZMd00wWGw6crUXemfPOn93HfsbuYx0vG1DKZbhh+AAsGBuHW5JjMcjH/nIP8lNj+VWJWH5VIioaTfjrv79DozoYhyrqUHCuDh8dPI2PDp52Lq/TKDF2QCjGxoS0hrMjoK12AS/sLcKrucVottoxJCwAT2WMx3+kDe31S16o7yRFBuG5eWlYNysFO4vK8VleEZZPS0P60ChJLy0j78UQ7qbiqgZ8c6ISuaXV+O5UFU6ev3AJilohx6S4CFw7JBLXDY3CtUMiEaHz65U6tGolrhsaheuGRjmn1TdboG8N5P8rLsX8q8dg7uhBCPXwa2n7ysAgLW5JDHXuLhJFEecam3HwXB0OVdS1PjoOHbSdcNNGpZDDahcwKFiLP2aMxYqrEqHuxh9S1L+olQrcOj4eQ201SEvkuS7UexjC3bA9/xQWv7XPOR7qr8ac0YNw3RBHGE6MDe+Ti7s7E+Kvxg1JA3FD0kDoQ8xIS0uQrJb+QCZzHHcfFKzFrFGDnNPNNjuOVjXg4Ll6ZzhXGVqw4upE3H1NkqT/xkTkXRjCXWQXBDz9eT5UCjn+PP8qTEmIwsioYO6i8kIapQLjY8IwPiZM6lKIyMsxhLvog4IyHKtpwl3XDMO91yZJXQ4REXkBnlHSBYIgYtPuQshlMjw2nd+hSUREPYMh3AX/OlyOQxX1WJw6BIkRPX/DByIi8k0MYTdEUcSGXYcAAKtmcCuYiIh6DkPYjV0lFfjxzHksGBuH0QNCpC6HiIi8CEPYjY27Hd988fgN3AomIqKexRC+hG9PVuGbE5W4eWQM0mLDpS6HiIi8DEP4EjbsdhwLfuLGsRJXQkRE3ogh3An9mfP44ug5TE2M7nBrSCIiop7CEO4Et4KJiKi3MYRdKPq5Hh8fOoOr48Jxw/ABUpdDREReym0IC4KAp59+GllZWVi6dCnKyso6zP/4448xb948LFmyBB988EGvFdqXNjnPiB7bL7+gnYiI+ge3Ibxr1y5YLBZs27YNDz/8MDZt2uScV1tbi7/85S9466238PbbbyM7Oxvl5eW9WnBvO1HThPcPnMLYgSGYO3qw1OUQEZEXcxvCer0e6enpAICUlBQUFhY655WXl2PkyJEICQmBXC7H2LFjUVBQ0HvV9oHn9hRCEEU8fsNYfkMSERH1KrchbDAYoNPpnOMKhQI2mw0AEB8fj+PHj6OmpgbNzc34/vvvYTKZeq/aXnamzoj/zTuJpMgg3Do+TupyiIjIy7n9KkOdTgej0egcFwQBSqXjacHBwXj88cfx29/+FgMGDMCYMWMQGhrq9kXbb033BL1e3yPr+VPez7DaBWQl6JB/4ECPrFNKPdUXb8O+uMa+uMa+uMa+uNbdvrgN4dTUVOzduxezZ89Gfn4+kpIufJeuzWZDQUEB3nnnHdhsNqxYsQIPPvig2xdNTk6GRqPpVqGd0ev1SEtLu+L1VDY145PtxYgLDcAfM6dDpejfJ473VF+8DfviGvviGvviGvviWmd9MZvNnW58ug3hjIwM5ObmYtGiRY5vFNqwAdnZ2TCZTMjKyoJKpcLChQuh0WiwYsUKhIWFXflvIoE/f3MELTY7Hps+pt8HMBER9Q9uQ1gul2Pt2rUdpiUmJjqHH3jgATzwwAM9X1kfqjWZ8dp3xRgQ6I8VVw+TuhwiIvIR3OQD8D/7jsJgtuGhqaPgp1JIXQ4REfkInw/hphYr/nvfUYRp1bjn2iT3TyAiIuohPh/Cf/u+BHXNFvxuyijoNCqpyyEiIh/i0yHcbLXhpW8OI1Cjwv3XjZC6HCIi8jE+HcL/2H8clU0tuP/6EQjV9swlU0RERF3lsyFssdnxwt4i+KsU+P2UUVKXQ0REPshnQ/htfSnO1Jtw9zXDEanzk7ocIiLyQT4Zwja7gOf2FEKtkOPhaaOlLoeIiHyUT4bwp0fO4nhNE5ZflYjBIQFSl0NERD7KJ0P4x9M1AIDbU+IlroSIiHyZT4bw4coGAMDo6BBpCyEiIp/mkyF8tLIBof5qRAfyhCwiIpKOz4Ww2WbH8fNNGB0dDJlMJnU5RETkw3wuhI9VN8IuiBg1IFjqUoiIyMf5XAi3HQ8eFcUQJiIiaflcCB9tC2GelEVERBLzuRC+cGY0t4SJiEhabkNYEAQ8/fTTyMrKwtKlS1FWVtZh/s6dO7FgwQJkZmbi3Xff7bVCe8qRygboNEoMDtFKXQoREfk4pbsFdu3aBYvFgm3btiE/Px+bNm3C5s2bnfOff/55/Otf/4JWq8WcOXMwZ84cBAd75lamzS6gpLoR42NCeWY0ERFJzm0I6/V6pKenAwBSUlJQWFjYYf6IESPQ1NQEpVIJURQ9OtxO1hpgsQsYxV3RRETkAdyGsMFggE6nc44rFArYbDYolY6nDh8+HJmZmfD390dGRgaCgoLcvugvg/xK6fX6Li339ZlGAECQzdDl5/RnvvA7Xg72xTX2xTX2xTX2xbXu9sVtCOt0OhiNRue4IAjOAD569Ci+/vpr7N69G1qtFo8++ig+//xzzJo165LrTE5Ohkaj6VahndHr9UhLS+vSsl/WHQJQjhtTRyNtTGyPvL6n6k5ffAn74hr74hr74hr74lpnfTGbzZ1ufLo9MSs1NRU5OTkAgPz8fCQlJTnnBQYGws/PDxqNBgqFAmFhYWhsbLzc+nvdkSreM5qIiDyH2y3hjIwM5ObmYtGiRRBFERs2bEB2djZMJhOysrKQlZWFJUuWQKVSIS4uDgsWLOiLui/LkcoG+CkVGBLGry8kIiLpuQ1huVyOtWvXdpiWmJjoHF68eDEWL17c85X1MEEQcaSyASOjgqCQ+9zl0URE5IF8Jo3K6gxottoxkmdGExGRh/CZED5S5ThWzTtlERGRp/CdEP65HgDvGU1ERJ7DZ0KY94wmIiJP4zMhfKSyAUq5DIkRgVKXQkREBMBHQlgURRypakBSZBBUCp/4lYmIqB/wiUQ619iMxhYr7xlNREQexSdC+HDrSVm8UxYREXkSnwjhI60nZY2Mdv/lEkRERH3FN0KY94wmIiIP5BshXNkAuUyGpEhuCRMRkefwiRA+/HMDEsN18FMppC6FiIjIyetDuNrQgvMmM+8ZTUREHsfrQ5h3yiIiIk/lAyFcD4D3jCYiIs/j9SF85GduCRMRkWdSultAEASsXr0axcXFUKvVWL9+PeLj4wEA1dXVeOihh5zLHjlyBA8//DAWL17cexV309HWy5NGRvHMaCIi8ixuQ3jXrl2wWCzYtm0b8vPzsWnTJmzevBkAEBkZibfeegsAcODAAbz88su4/fbbe7fibjpc2YD40AAEaFRSl0JERNSB293Rer0e6enpAICUlBQUFhZetIwoili3bh1Wr14NhcJzLgOqM5lR0djMe0YTEZFHchvCBoMBOp3OOa5QKGCz2Toss2fPHgwfPhwJCQk9X+EVaLtdJUOYiIg8kdvd0TqdDkaj0TkuCAKUyo5P27lzJ5YtW9blF3W1NX0l9Hq9y+n/PlEHANC21He6jDfzxd+5K9gX19gX19gX19gX17rbF7chnJqair1792L27NnIz89HUlLSRcsUFRUhNTW1yy+anJwMjUbTrUI7o9frkZaW5nLee2fzAFRg1tXjkTYkskder7+4VF98GfviGvviGvviGvviWmd9MZvNnW58ug3hjIwM5ObmYtGiRRBFERs2bEB2djZMJhOysrJQW1uLgIAAyGSyK/8Nethh7o4mIiIP5jaE5XI51q5d22FaYmKiczgsLAyffPJJz1fWA45UNmBgkD9C/NVSl0JERHQRr71Zh8Fsxek6I2/SQUREHstrQ/hoVSMA7oomIiLP5bUhzHtGExGRp/PaEG67ZzS3hImIyFN5bwhX8YsbiIjIs3lvCFc2ICJAg0idn9SlEBERueSVIdxitePkeQO3gomIyKN5ZQiXVDdCEEWMZAgTEZEH88oQbjszmlvCRETkybwyhC98e1KItIUQERFdgleGcNs9o7klTEREnswrQ/hoZQOC/FQYGOQvdSlERESd8roQttoFlFQ3YnR0sEd+sxMREVEbrwvh4zVNsAki75RFREQez+tC+MKZ0SGS1kFEROSO14Xw0daTsniNMBEReTqvC2GeGU1ERP2F0t0CgiBg9erVKC4uhlqtxvr16xEfH++cf/DgQWzatAmiKCIyMhIvvPACNBpNrxZ9KUcqG6BVKxAXEiBZDURERF3hdkt4165dsFgs2LZtGx5++GFs2rTJOU8URTz11FPYuHEj3nvvPaSnp+Ps2bO9WvCl2AUBR6saMDIqGHI5z4wmIiLP5nZLWK/XIz09HQCQkpKCwsJC57zS0lKEhIRg69atKCkpwdSpU5GQkNB71bpxqtYIs03gmdFERNQvuA1hg8EAnU7nHFcoFLDZbFAqlairq8OBAwfw1FNPIT4+Hvfeey+Sk5MxefLkS66zfZD3BL1eDwDYV94EAAi2GZ3TfBl74Br74hr74hr74hr74lp3++I2hHU6HYxGo3NcEAQolY6nhYSEID4+HsOGDQMApKeno7Cw0G0IJycn99hxY71ej7S0NADA7oZCAGdwY+popCXH9sj6+6v2faEL2BfX2BfX2BfX2BfXOuuL2WzudOPT7THh1NRU5OTkAADy8/ORlJTknBcbGwuj0YiysjIAQF5eHoYPH35ZxfeEw84vbuDuaCIi8nxut4QzMjKQm5uLRYsWQRRFbNiwAdnZ2TCZTMjKysKzzz6Lhx9+GKIoYsKECZg2bVoflO3a0coGqBVyJITp3C9MREQkMbchLJfLsXbt2g7TEhMTncOTJ0/Gjh07er6ybhJFEYcrGzAiKghKhddd/kxERF7Ia9LqTL0JRouNu6KJiKjf8JoQPtJ2PDiKIUxERP2DF4VwPQBg1IAQSesgIiLqKq8JYd4zmoiI+huvCeEjlQ1QyGUYHhEodSlERERd4hUhLIoijlQ2YFh4INRKhdTlEBERdYlXhHBlUwvqmi0YNYC7oomIqP/wihA+3HpSFo8HExFRf+IVIey8PCk6RNpCiIiIusG7QpjXCBMRUT/iNSEskwEjooKkLoWIiKjLvCKED1c2YGiYDlq121thExEReYx+H8L1ZhuqDC28ZzQREfU7/T6ETzVYAPB4MBER9T/9PoRLG80AeGY0ERH1P/0/hBscITyaN+ogIqJ+xmtCeCTPjCYion7G7enEgiBg9erVKC4uhlqtxvr16xEfH++c/+abb2LHjh0ICwsDAKxZswYJCQm9V/EvlDaaMThYiyA/dZ+9JhERUU9wG8K7du2CxWLBtm3bkJ+fj02bNmHz5s3O+UVFRXjuueeQnJzcq4W60thiQZXJhoykyD5/bSIioivlNoT1ej3S09MBACkpKSgsLOwwv6ioCK+//jqqq6sxbdo03HPPPb1TqQttd8ri8WAiIuqP3IawwWCATqdzjisUCthsNiiVjqfOmTMHS5YsgU6nwwMPPIC9e/di+vTpl1znL4P8cuWcbgQA6MwN0Ov1PbJOb8KeuMa+uMa+uMa+uMa+uNbdvrgNYZ1OB6PR6BwXBMEZwKIoYvny5QgMDAQATJ06FYcPH3YbwsnJydBoNN0q1JURyVY0WL7B4wumwV/Fu2W1p9frkZaWJnUZHod9cY19cY19cY19ca2zvpjN5k43Pt2eHZ2amoqcnBwAQH5+PpKSkpzzDAYD5s6dC6PRCFEUsX///j49NqzTqLBgWCgDmIiI+iW36ZWRkYHc3FwsWrQIoihiw4YNyM7OhslkQlZWFh588EEsW7YMarUakydPxtSpU/uibiIion7PbQjL5XKsXbu2w7TExETn8Pz58zF//vweL4yIiMjb9fubdRAREfVXfXowVRRFAIDFYunR9ZrN5h5dn7dgX1xjX1xjX1xjX1xjX1xz1Ze2zGvLwPZkoqupvaSpqQklJSV99XJEREQeIykpyXk1UZs+DWFBEGA0GqFSqSCTyfrqZYmIiCQjiiKsVisCAgIgl3c8CtynIUxEREQX8MQsIiIiiTCEiYiIJMIQJiIikghDmIiISCL99qbLgiBg9erVKC4uhlqtxvr16xEfHy91WR5h/vz5ztPgBw8ejI0bN0pckbQKCgrw4osv4q233kJZWRlWrVoFmUyG4cOH45lnnrnobEVf0b4vRUVFuPfeezFkyBAAwOLFizF79mxpC+xjVqsVTzzxBM6ePQuLxYL77rsPw4YN8/n3i6u+DBgwwOffL3a7HU8++SRKS0uhUCiwceNGiKLY7fdLvw3hXbt2wWKxYNu2bcjPz8emTZuwefNmqcuSXNuF4m+99ZbElXiGLVu2YOfOnfD39wcAbNy4Eb///e8xadIkPP3009i9ezcyMjIkrrLv/bIvhw8fxooVK3DnnXdKXJl0du7ciZCQELzwwguoq6vDggULMHLkSJ9/v7jqy/333+/z75e9e/cCAN5//33s37/fGcLdfb/02z/p9Ho90tPTAQApKSk99h3F/d3Ro0fR3NyMO++8E8uWLUN+fr7UJUkqLi4Or7zyinO8qKgIV199NQBgypQp+O6776QqTVK/7EthYSG+/vpr3HHHHXjiiSdgMBgkrE4aN998M373u985xxUKBd8vcN0Xvl+AG2+8EevWrQMAnDt3DhEREZf1fum3IWwwGKDT6ZzjCoUCNptNwoo8g5+fH1auXIk33ngDa9aswSOPPOLTfZk5c6bz+68Bx0XzbTeKCQgIQFNTk1SlSeqXfRk3bhwee+wxvPPOO4iNjcWrr74qYXXSCAgIgE6ng8FgwH/913/h97//Pd8vcN0Xvl8clEol/vCHP2DdunWYOXPmZb1f+m0I63Q6GI1G57ggCB0+VHzV0KFDccstt0Amk2Ho0KEICQlBdXW11GV5jPbHZ4xGI4KCgiSsxnNkZGQ4vws8IyMDhw8flrgiaVRUVGDZsmX41a9+hXnz5vH90uqXfeH75YLnnnsOX3zxBZ566qkO943u6vul34ZwamoqcnJyAAD5+flISkqSuCLPsGPHDmzatAkAUFlZCYPBgMjISImr8hyjR4/G/v37AQA5OTmYOHGixBV5hpUrV+LgwYMAgO+//x5jxoyRuKK+V1NTgzvvvBOPPvoobr31VgB8vwCu+8L3C/Dxxx/jb3/7GwDA398fMpkMycnJ3X6/9NvbVradHV1SUgJRFLFhw4YO33PsqywWCx5//HGcO3cOMpkMjzzyCFJTU6UuS1Ll5eV46KGHsH37dpSWluKpp56C1WpFQkIC1q9fD4VCIXWJkmjfl6KiIqxbtw4qlQoRERFYt25dh8M9vmD9+vX4/PPPkZCQ4Jz2xz/+EevXr/fp94urvvz+97/HCy+84NPvF5PJhMcffxw1NTWw2Wy4++67kZiY2O3Pl34bwkRERP1dv90dTURE1N8xhImIiCTCECYiIpIIQ5iIiEgiDGEiIiKJMISJiIgkwhAmIiKSCEOYiIhIIv8fxmz8SKuHKegAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "# plt.plot(history.history['val_loss'], label=\"validation\")\n",
    "plt.plot(history.history['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "# plt.plot(history.history['val_categorical_accuracy'],label=\"validation\")\n",
    "plt.plot(history.history['categorical_accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models_output/lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"../models_output/lstm_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test (no need for model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "rock&roll\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "circle_arm\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ultraman\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "ultraman\n",
      "HERE\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "frames = []\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hoslistic:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: # if capture frame failed then skip the logic below and retry\n",
    "            continue\n",
    "\n",
    "        # Copy frame\n",
    "        img = frame.copy()\n",
    "        img = cv2.cvtColor(cv2.flip(img,1),cv2.COLOR_BGR2RGB) # Set frame color to RGB to process\n",
    "        # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        # input_img = tf.cast(img, dtype=tf.int32)\n",
    "        img.flags.writeable = False\n",
    "        # Detection section\n",
    "        results = hoslistic.process(img)\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) # set back to original color\n",
    "        # draw keypoints to the frame\n",
    "        mp_drawing.draw_landmarks(img,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        keypoints = keypointsToNumPy(results)\n",
    "        frames.append(keypoints)\n",
    "        # just get last 30 frames\n",
    "        frames = frames[-15:]\n",
    "        if len(frames) == 15:\n",
    "            a = np.array(frames)\n",
    "            # convert it to proper input (1,30,258)\n",
    "            print(np.expand_dims(frames,axis=0).shape)\n",
    "            # get the first prediction as we only pass one into it\n",
    "            r = model.predict(np.expand_dims(frames,axis=0))[0]\n",
    "\n",
    "            print(actions[np.argmax(r)])\n",
    "            cv2.putText(img,f'Action {actions[np.argmax(r)]}',(20,70),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2,cv2.LINE_AA,False)\n",
    "        cv2.imshow('Testing Final Model', img)\n",
    "         #This breaks on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "print(\"HERE\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = keras.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    n_classes = len(actions)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3990, 5)\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 15s 124ms/step - loss: 1.5541 - categorical_accuracy: 0.2336 - val_loss: 1.3358 - val_categorical_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 1.1478 - categorical_accuracy: 0.4223 - val_loss: 0.9084 - val_categorical_accuracy: 0.5190\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.9505 - categorical_accuracy: 0.5090 - val_loss: 0.7931 - val_categorical_accuracy: 0.5571\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.8332 - categorical_accuracy: 0.5674 - val_loss: 0.7296 - val_categorical_accuracy: 0.5524\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.7986 - categorical_accuracy: 0.6030 - val_loss: 0.7359 - val_categorical_accuracy: 0.5762\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.7605 - categorical_accuracy: 0.6206 - val_loss: 0.7418 - val_categorical_accuracy: 0.6048\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 0.6803 - categorical_accuracy: 0.6757 - val_loss: 0.5804 - val_categorical_accuracy: 0.7333\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.5973 - categorical_accuracy: 0.7356 - val_loss: 0.5859 - val_categorical_accuracy: 0.7190\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.5549 - categorical_accuracy: 0.7799 - val_loss: 0.5108 - val_categorical_accuracy: 0.8095\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.5344 - categorical_accuracy: 0.7962 - val_loss: 0.4861 - val_categorical_accuracy: 0.7619\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.4997 - categorical_accuracy: 0.8311 - val_loss: 0.4268 - val_categorical_accuracy: 0.8810\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.4359 - categorical_accuracy: 0.8607 - val_loss: 0.3883 - val_categorical_accuracy: 0.9095\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.4312 - categorical_accuracy: 0.8679 - val_loss: 0.4096 - val_categorical_accuracy: 0.9429\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.4895 - categorical_accuracy: 0.8554 - val_loss: 0.4117 - val_categorical_accuracy: 0.9476\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6209 - categorical_accuracy: 0.8078 - val_loss: 0.4176 - val_categorical_accuracy: 0.8952\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.3812 - categorical_accuracy: 0.9173 - val_loss: 0.3040 - val_categorical_accuracy: 0.9619\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3686 - categorical_accuracy: 0.9183 - val_loss: 0.2853 - val_categorical_accuracy: 0.9810\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.3273 - categorical_accuracy: 0.9308 - val_loss: 0.2625 - val_categorical_accuracy: 0.9810\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.3167 - categorical_accuracy: 0.9376 - val_loss: 0.2543 - val_categorical_accuracy: 0.9571\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.2678 - categorical_accuracy: 0.9571 - val_loss: 0.2069 - val_categorical_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.2304 - categorical_accuracy: 0.9692 - val_loss: 0.1796 - val_categorical_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2248 - categorical_accuracy: 0.9684 - val_loss: 0.2033 - val_categorical_accuracy: 0.9857\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2054 - categorical_accuracy: 0.9752 - val_loss: 0.1606 - val_categorical_accuracy: 0.9952\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.5844 - categorical_accuracy: 0.8333 - val_loss: 0.5119 - val_categorical_accuracy: 0.8524\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 0.3569 - categorical_accuracy: 0.9055 - val_loss: 0.1547 - val_categorical_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.1748 - categorical_accuracy: 0.9825 - val_loss: 0.1279 - val_categorical_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.2637 - categorical_accuracy: 0.9391 - val_loss: 0.1920 - val_categorical_accuracy: 0.9857\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.1722 - categorical_accuracy: 0.9767 - val_loss: 0.1200 - val_categorical_accuracy: 0.9952\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 0.1407 - categorical_accuracy: 0.9840 - val_loss: 0.1180 - val_categorical_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.1275 - categorical_accuracy: 0.9890 - val_loss: 0.0894 - val_categorical_accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.0894 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08944027125835419, 1.0]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "print(Y_train.shape)\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=2,\n",
    "    ff_dim=2,\n",
    "    num_transformer_blocks=2,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    # validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=40,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test)\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0894 - categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08944027125835419, 1.0]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 6, 1662)]    0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_68 (LayerN  (None, 6, 1662)     3324        ['input_18[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_34 (Multi  (None, 6, 1662)     3406974     ['layer_normalization_68[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 6, 1662)      0           ['multi_head_attention_34[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_68 (TFOpL  (None, 6, 1662)     0           ['dropout_91[0][0]',             \n",
      " ambda)                                                           'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_69 (LayerN  (None, 6, 1662)     3324        ['tf.__operators__.add_68[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_68 (Conv1D)             (None, 6, 2)         3326        ['layer_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 6, 2)         0           ['conv1d_68[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_69 (Conv1D)             (None, 6, 1662)      4986        ['dropout_92[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_69 (TFOpL  (None, 6, 1662)     0           ['conv1d_69[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_68[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_70 (LayerN  (None, 6, 1662)     3324        ['tf.__operators__.add_69[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_35 (Multi  (None, 6, 1662)     3406974     ['layer_normalization_70[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 6, 1662)      0           ['multi_head_attention_35[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_70 (TFOpL  (None, 6, 1662)     0           ['dropout_93[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_69[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_71 (LayerN  (None, 6, 1662)     3324        ['tf.__operators__.add_70[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_70 (Conv1D)             (None, 6, 2)         3326        ['layer_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 6, 2)         0           ['conv1d_70[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_71 (Conv1D)             (None, 6, 1662)      4986        ['dropout_94[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_71 (TFOpL  (None, 6, 1662)     0           ['conv1d_71[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_70[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_17 (G  (None, 6)           0           ['tf.__operators__.add_71[0][0]']\n",
      " lobalAveragePooling1D)                                                                           \n",
      "                                                                                                  \n",
      " dense_58 (Dense)               (None, 128)          896         ['global_average_pooling1d_17[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 128)          0           ['dense_58[0][0]']               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 5)            645         ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,845,409\n",
      "Trainable params: 6,845,409\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['val_loss'], label=\"validation\")\n",
    "plt.plot(history.history['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.50,1.00,1.50])\n",
    "plt.title('Loss value',fontsize=12)\n",
    "\n",
    "ax          = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['val_categorical_accuracy'],label=\"validation\")\n",
    "plt.plot(history.history['categorical_accuracy'],label=\"training\")\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.title('Accuracy',fontsize=12)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 34ms/step\n",
      "[[50  0  0  0  0]\n",
      " [ 0 34  0  0  0]\n",
      " [ 0  0 44  0  0]\n",
      " [ 0  0  0 46  0]\n",
      " [ 0  0  0  0 36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        46\n",
      "           4       1.00      1.00      1.00        36\n",
      "\n",
      "    accuracy                           1.00       210\n",
      "   macro avg       1.00      1.00      1.00       210\n",
      "weighted avg       1.00      1.00      1.00       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(Y_test,axis=1)\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "--- Average prediction time in 100 samples : 85ms, min: 71ms, max: 226ms ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# start_time = time.time()\n",
    "# print(np.expand_dims(X_test[0],axis=0).shape)\n",
    "# print(X_test[0].shape)\n",
    "# y_pred = model.predict(np.expand_dims(X_test[0],axis=0))\n",
    "# print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "times = []\n",
    "minTime = float(\"inf\")\n",
    "maxTime = float(\"-inf\")\n",
    "for i in range(100):\n",
    "    input = np.expand_dims(X_test[i],axis=0)\n",
    "    start_time = time.time()\n",
    "    model.predict(input)\n",
    "    total_time = time.time() - start_time\n",
    "    if total_time > maxTime:\n",
    "        maxTime = total_time\n",
    "    if total_time < minTime:\n",
    "        minTime=total_time\n",
    "    times.append(total_time)\n",
    "\n",
    "print(\"--- Average prediction time in 100 samples : %sms, min: %sms, max: %sms ---\" % (int(np.average(times) * 1000),int(minTime * 1000),int(maxTime * 1000)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.57824531e-01, 1.50229444e-03, 8.19186091e-01, 1.43900439e-02,\n",
       "        7.09709479e-03],\n",
       "       [1.25656230e-03, 1.20561235e-01, 1.43559696e-02, 8.25449824e-01,\n",
       "        3.83764207e-02],\n",
       "       [2.24670907e-17, 9.99908686e-01, 7.55007981e-13, 8.91218515e-05,\n",
       "        2.17597403e-06],\n",
       "       ...,\n",
       "       [9.07270886e-18, 1.88234765e-07, 2.44330770e-14, 1.62201041e-09,\n",
       "        9.99999762e-01],\n",
       "       [9.98842835e-01, 3.47244643e-23, 1.15710811e-03, 7.57909002e-21,\n",
       "        2.46509314e-18],\n",
       "       [1.77208528e-01, 8.35513347e-04, 8.08972955e-01, 8.47077835e-03,\n",
       "        4.51216800e-03]], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try larger dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 30, 258)]    0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_40 (LayerN  (None, 30, 258)     516         ['input_6[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (Multi  (None, 30, 258)     1060098     ['layer_normalization_40[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_20[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_40 (TFOpL  (None, 30, 258)     0           ['dropout_45[0][0]',             \n",
      " ambda)                                                           'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_41 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_40[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 30, 4)        0           ['conv1d_40[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 30, 258)      1290        ['dropout_46[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_41 (TFOpL  (None, 30, 258)     0           ['conv1d_41[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_40[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_42 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_41[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (Multi  (None, 30, 258)     1060098     ['layer_normalization_42[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_21[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (TFOpL  (None, 30, 258)     0           ['dropout_47[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_41[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_43 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_42[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 30, 4)        0           ['conv1d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 30, 258)      1290        ['dropout_48[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_43 (TFOpL  (None, 30, 258)     0           ['conv1d_43[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_42[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_44 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_43[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (Multi  (None, 30, 258)     1060098     ['layer_normalization_44[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_22[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_44 (TFOpL  (None, 30, 258)     0           ['dropout_49[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_43[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_45 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_44[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 30, 4)        0           ['conv1d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 30, 258)      1290        ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_45 (TFOpL  (None, 30, 258)     0           ['conv1d_45[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_44[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_46 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_45[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (Multi  (None, 30, 258)     1060098     ['layer_normalization_46[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_23[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_46 (TFOpL  (None, 30, 258)     0           ['dropout_51[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_45[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_47 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_46[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 30, 4)        0           ['conv1d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 30, 258)      1290        ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_47 (TFOpL  (None, 30, 258)     0           ['conv1d_47[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_46[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 30)          0           ['tf.__operators__.add_47[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 128)          3968        ['global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 128)          0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 5)            645         ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,258,437\n",
      "Trainable params: 4,258,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 15s 293ms/step - loss: 1.5392 - categorical_accuracy: 0.2596 - val_loss: 1.2259 - val_categorical_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 1.4139 - categorical_accuracy: 0.3035 - val_loss: 0.9894 - val_categorical_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 7s 239ms/step - loss: 1.3154 - categorical_accuracy: 0.3789 - val_loss: 0.8958 - val_categorical_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 7s 238ms/step - loss: 1.2104 - categorical_accuracy: 0.4088 - val_loss: 0.8366 - val_categorical_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 7s 227ms/step - loss: 1.1707 - categorical_accuracy: 0.3930 - val_loss: 0.8059 - val_categorical_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 1.1468 - categorical_accuracy: 0.4246 - val_loss: 0.7841 - val_categorical_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 1.1063 - categorical_accuracy: 0.4404 - val_loss: 0.7697 - val_categorical_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 1.0648 - categorical_accuracy: 0.4439 - val_loss: 0.7459 - val_categorical_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.9684 - categorical_accuracy: 0.5246 - val_loss: 0.7631 - val_categorical_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.9231 - categorical_accuracy: 0.5386 - val_loss: 0.8500 - val_categorical_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 6s 218ms/step - loss: 0.8895 - categorical_accuracy: 0.5509 - val_loss: 0.6672 - val_categorical_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.8056 - categorical_accuracy: 0.6070 - val_loss: 0.6443 - val_categorical_accuracy: 0.6333\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.7407 - categorical_accuracy: 0.6228 - val_loss: 0.5434 - val_categorical_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.7670 - categorical_accuracy: 0.6175 - val_loss: 0.5488 - val_categorical_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.7319 - categorical_accuracy: 0.6228 - val_loss: 0.5592 - val_categorical_accuracy: 0.6333\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.6967 - categorical_accuracy: 0.6614 - val_loss: 0.5809 - val_categorical_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.6616 - categorical_accuracy: 0.6719 - val_loss: 0.6218 - val_categorical_accuracy: 0.7667\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.6718 - categorical_accuracy: 0.6667 - val_loss: 0.7991 - val_categorical_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.6559 - categorical_accuracy: 0.6632 - val_loss: 0.5257 - val_categorical_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.5918 - categorical_accuracy: 0.7263 - val_loss: 0.9759 - val_categorical_accuracy: 0.6333\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.6531 - categorical_accuracy: 0.6772 - val_loss: 0.5557 - val_categorical_accuracy: 0.6333\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 7s 236ms/step - loss: 0.6036 - categorical_accuracy: 0.7211 - val_loss: 0.5563 - val_categorical_accuracy: 0.6333\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.5858 - categorical_accuracy: 0.7509 - val_loss: 0.5465 - val_categorical_accuracy: 0.6667\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.5385 - categorical_accuracy: 0.7614 - val_loss: 0.5666 - val_categorical_accuracy: 0.6667\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 199s 7s/step - loss: 0.5473 - categorical_accuracy: 0.7386 - val_loss: 1.0988 - val_categorical_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 7s 235ms/step - loss: 0.5081 - categorical_accuracy: 0.7807 - val_loss: 0.6517 - val_categorical_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 7s 233ms/step - loss: 0.5006 - categorical_accuracy: 0.7825 - val_loss: 0.6946 - val_categorical_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 8s 270ms/step - loss: 0.4758 - categorical_accuracy: 0.8123 - val_loss: 0.8652 - val_categorical_accuracy: 0.7333\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 7s 259ms/step - loss: 0.4310 - categorical_accuracy: 0.8123 - val_loss: 1.0178 - val_categorical_accuracy: 0.6667\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5257 - categorical_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5256912708282471, 0.6666666865348816]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.5,\n",
    "    dropout=0.5,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=20,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test)\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 30, 258)]    0           []                               \n",
      "                                                                                                  \n",
      " layer_normalization_32 (LayerN  (None, 30, 258)     516         ['input_5[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (Multi  (None, 30, 258)     1060098     ['layer_normalization_32[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_16[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (TFOpL  (None, 30, 258)     0           ['dropout_36[0][0]',             \n",
      " ambda)                                                           'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_33 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_32[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 30, 4)        0           ['conv1d_32[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 30, 258)      1290        ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (TFOpL  (None, 30, 258)     0           ['conv1d_33[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_32[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_34 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_33[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (Multi  (None, 30, 258)     1060098     ['layer_normalization_34[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_17[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (TFOpL  (None, 30, 258)     0           ['dropout_38[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_33[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_35 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_34[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 30, 4)        0           ['conv1d_34[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 30, 258)      1290        ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (TFOpL  (None, 30, 258)     0           ['conv1d_35[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_34[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_36 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_35[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (Multi  (None, 30, 258)     1060098     ['layer_normalization_36[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_18[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (TFOpL  (None, 30, 258)     0           ['dropout_40[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_35[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_37 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_36[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 30, 4)        0           ['conv1d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 30, 258)      1290        ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (TFOpL  (None, 30, 258)     0           ['conv1d_37[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_36[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_38 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_37[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (Multi  (None, 30, 258)     1060098     ['layer_normalization_38[0][0]', \n",
      " HeadAttention)                                                   'layer_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 30, 258)      0           ['multi_head_attention_19[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add_38 (TFOpL  (None, 30, 258)     0           ['dropout_42[0][0]',             \n",
      " ambda)                                                           'tf.__operators__.add_37[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_39 (LayerN  (None, 30, 258)     516         ['tf.__operators__.add_38[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 30, 4)        1036        ['layer_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 30, 4)        0           ['conv1d_38[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 30, 258)      1290        ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_39 (TFOpL  (None, 30, 258)     0           ['conv1d_39[0][0]',              \n",
      " ambda)                                                           'tf.__operators__.add_38[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 30)          0           ['tf.__operators__.add_39[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 128)          3968        ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 128)          0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 5)            645         ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,258,437\n",
      "Trainable params: 4,258,437\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/60\n",
      "29/29 [==============================] - 13s 267ms/step - loss: 1.4014 - categorical_accuracy: 0.3526 - val_loss: 1.2092 - val_categorical_accuracy: 0.1667\n",
      "Epoch 2/60\n",
      "29/29 [==============================] - 7s 248ms/step - loss: 0.9941 - categorical_accuracy: 0.4649 - val_loss: 1.2575 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/60\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.9126 - categorical_accuracy: 0.5158 - val_loss: 1.0690 - val_categorical_accuracy: 0.5000\n",
      "Epoch 4/60\n",
      "29/29 [==============================] - 6s 221ms/step - loss: 0.8293 - categorical_accuracy: 0.5842 - val_loss: 0.9385 - val_categorical_accuracy: 0.5000\n",
      "Epoch 5/60\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.6907 - categorical_accuracy: 0.7158 - val_loss: 0.9784 - val_categorical_accuracy: 0.5667\n",
      "Epoch 6/60\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.6879 - categorical_accuracy: 0.7193 - val_loss: 0.7719 - val_categorical_accuracy: 0.5667\n",
      "Epoch 7/60\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.5897 - categorical_accuracy: 0.8140 - val_loss: 0.6078 - val_categorical_accuracy: 0.9667\n",
      "Epoch 8/60\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.5253 - categorical_accuracy: 0.8754 - val_loss: 0.6554 - val_categorical_accuracy: 0.8333\n",
      "Epoch 9/60\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.4650 - categorical_accuracy: 0.8877 - val_loss: 0.4870 - val_categorical_accuracy: 0.9667\n",
      "Epoch 10/60\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.4004 - categorical_accuracy: 0.9263 - val_loss: 0.6289 - val_categorical_accuracy: 0.7667\n",
      "Epoch 11/60\n",
      "29/29 [==============================] - 6s 205ms/step - loss: 0.4166 - categorical_accuracy: 0.8456 - val_loss: 1.2865 - val_categorical_accuracy: 0.8667\n",
      "Epoch 12/60\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3240 - categorical_accuracy: 0.9175 - val_loss: 0.9584 - val_categorical_accuracy: 0.6000\n",
      "Epoch 13/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.2722 - categorical_accuracy: 0.9281 - val_loss: 0.3025 - val_categorical_accuracy: 0.9333\n",
      "Epoch 14/60\n",
      "29/29 [==============================] - 6s 204ms/step - loss: 0.3067 - categorical_accuracy: 0.8895 - val_loss: 0.5273 - val_categorical_accuracy: 0.8667\n",
      "Epoch 15/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.2421 - categorical_accuracy: 0.9298 - val_loss: 0.2653 - val_categorical_accuracy: 0.9333\n",
      "Epoch 16/60\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.2068 - categorical_accuracy: 0.9509 - val_loss: 0.2791 - val_categorical_accuracy: 0.9667\n",
      "Epoch 17/60\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.1956 - categorical_accuracy: 0.9579 - val_loss: 0.1882 - val_categorical_accuracy: 0.9667\n",
      "Epoch 18/60\n",
      "29/29 [==============================] - 6s 206ms/step - loss: 0.1609 - categorical_accuracy: 0.9526 - val_loss: 0.2170 - val_categorical_accuracy: 0.9667\n",
      "Epoch 19/60\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.1576 - categorical_accuracy: 0.9702 - val_loss: 0.1785 - val_categorical_accuracy: 0.9667\n",
      "Epoch 20/60\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.1362 - categorical_accuracy: 0.9719 - val_loss: 0.2507 - val_categorical_accuracy: 0.9333\n",
      "Epoch 21/60\n",
      "29/29 [==============================] - 6s 215ms/step - loss: 0.0872 - categorical_accuracy: 0.9912 - val_loss: 0.1020 - val_categorical_accuracy: 0.9667\n",
      "Epoch 22/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.0708 - categorical_accuracy: 0.9895 - val_loss: 0.1041 - val_categorical_accuracy: 0.9667\n",
      "Epoch 23/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.0740 - categorical_accuracy: 0.9895 - val_loss: 0.1129 - val_categorical_accuracy: 0.9667\n",
      "Epoch 24/60\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.0578 - categorical_accuracy: 0.9965 - val_loss: 0.0821 - val_categorical_accuracy: 0.9667\n",
      "Epoch 25/60\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.0592 - categorical_accuracy: 0.9895 - val_loss: 0.1310 - val_categorical_accuracy: 0.9667\n",
      "Epoch 26/60\n",
      "29/29 [==============================] - 6s 208ms/step - loss: 0.0536 - categorical_accuracy: 0.9947 - val_loss: 0.1331 - val_categorical_accuracy: 0.9667\n",
      "Epoch 27/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.0684 - categorical_accuracy: 0.9877 - val_loss: 0.6637 - val_categorical_accuracy: 0.8000\n",
      "Epoch 28/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 4.2515 - categorical_accuracy: 0.5088 - val_loss: 3.5266 - val_categorical_accuracy: 0.4667\n",
      "Epoch 29/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 2.1231 - categorical_accuracy: 0.6175 - val_loss: 2.2541 - val_categorical_accuracy: 0.5000\n",
      "Epoch 30/60\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.8276 - categorical_accuracy: 0.7281 - val_loss: 0.7953 - val_categorical_accuracy: 0.6667\n",
      "Epoch 31/60\n",
      "29/29 [==============================] - 6s 210ms/step - loss: 0.4520 - categorical_accuracy: 0.8333 - val_loss: 0.3831 - val_categorical_accuracy: 0.8000\n",
      "Epoch 32/60\n",
      "29/29 [==============================] - 6s 209ms/step - loss: 0.3136 - categorical_accuracy: 0.8982 - val_loss: 0.4585 - val_categorical_accuracy: 0.8333\n",
      "Epoch 33/60\n",
      "29/29 [==============================] - 6s 207ms/step - loss: 0.2576 - categorical_accuracy: 0.9175 - val_loss: 0.4579 - val_categorical_accuracy: 0.8000\n",
      "Epoch 34/60\n",
      "29/29 [==============================] - 6s 216ms/step - loss: 0.3421 - categorical_accuracy: 0.8754 - val_loss: 0.4784 - val_categorical_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 0.0821 - categorical_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08212970197200775, 0.9666666388511658]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\"categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=80,\n",
    "    batch_size=20,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test)\n",
    ")\n",
    "\n",
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models_output/transformer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"../models_output/transformer_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Wakanda\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Wakanda\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Left_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "no_action\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "kiss\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Right_punch\n",
      "(1, 15, 258)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Right_punch\n",
      "HERE\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "frames = []\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hoslistic:\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success: # if capture frame failed then skip the logic below and retry\n",
    "            continue\n",
    "\n",
    "        # Copy frame\n",
    "        img = frame.copy()\n",
    "        img = cv2.cvtColor(cv2.flip(img,1),cv2.COLOR_BGR2RGB) # Set frame color to RGB to process\n",
    "        # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        # input_img = tf.cast(img, dtype=tf.int32)\n",
    "        img.flags.writeable = False\n",
    "        # Detection section\n",
    "        results = hoslistic.process(img)\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2BGR) # set back to original color\n",
    "        # draw keypoints to the frame\n",
    "        mp_drawing.draw_landmarks(img,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        mp_drawing.draw_landmarks(img,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "        keypoints = keypointsToNumPy(results)\n",
    "        frames.append(keypoints)\n",
    "        # just get last 30 frames\n",
    "        frames = frames[-15:]\n",
    "        if len(frames) == 15:\n",
    "            a = np.array(frames)\n",
    "            # convert it to proper input (1,30,258)\n",
    "            print(np.expand_dims(frames,axis=0).shape)\n",
    "            # get the first prediction as we only pass one into it\n",
    "            r = model.predict(np.expand_dims(frames,axis=0))[0]\n",
    "\n",
    "            print(actions[np.argmax(r)])\n",
    "            cv2.putText(img,f'Action {actions[np.argmax(r)]}',(20,70),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),2,cv2.LINE_AA,False)\n",
    "        cv2.imshow('Testing Final Model', img)\n",
    "         #This breaks on 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "print(\"HERE\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "from attrdict import AttrDict\n",
    "\n",
    "\n",
    "async def echo(websocket):\n",
    "    frames = []\n",
    "    async for message in websocket:\n",
    "        # print(message)\n",
    "        try:\n",
    "            y = json.loads(message)\n",
    "            results = AttrDict({\n",
    "                \"pose_landmarks\":{\n",
    "                    \"landmark\":[]\n",
    "                },\n",
    "                \"left_hand_landmarks\":{\n",
    "                    \"landmark\":[]\n",
    "                },\n",
    "                \"right_hand_landmarks\":{\n",
    "                    \"landmark\":[]\n",
    "                }\n",
    "            })\n",
    "            results[\"pose_landmarks\"][\"landmark\"] = y[\"poseLandmarks\"]\n",
    "            if \"leftHandLandmarks\" in y:\n",
    "                results[\"left_hand_landmarks\"][\"landmark\"] = y[\"leftHandLandmarks\"]\n",
    "            if \"rightHandLandmarks\" in y:\n",
    "                results[\"right_hand_landmarks\"][\"landmark\"] = y[\"rightHandLandmarks\"]\n",
    "            keypoints = keypointsToNumPy(results)\n",
    "            frames.append(keypoints)\n",
    "            # just get last 30 frames\n",
    "            frames = frames[-30:]\n",
    "            if len(frames) == 30:\n",
    "                a = np.array(frames)\n",
    "                # convert it to proper input (1,30,258)\n",
    "                print(np.expand_dims(frames,axis=0).shape)\n",
    "                # get the first prediction as we only pass one into it\n",
    "                r = model.predict(np.expand_dims(frames,axis=0))[0]\n",
    "                r[r<0.5] = 0\n",
    "                print(actions[np.argmax(r)])\n",
    "                await websocket.send(actions[np.argmax(r)] + \",\" + str(r))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        # await websocket.send(message + \"server\")\n",
    "\n",
    "async def main():\n",
    "    async with websockets.serve(echo, \"localhost\", 8765):\n",
    "        await asyncio.Future()  # run forever\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-22 16:42:53.703028: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('transformer.h5')\n",
    "frames = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(258,)\n"
     ]
    }
   ],
   "source": [
    "from attrdict import AttrDict\n",
    "j = {\n",
    "    \"image\": {},\n",
    "    \"poseLandmarks\": [\n",
    "        {\n",
    "            \"x\": 0.5880926847457886,\n",
    "            \"y\": 0.25798192620277405,\n",
    "            \"z\": -0.3409603238105774,\n",
    "            \"visibility\": 0.8919544816017151\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5906530618667603,\n",
    "            \"y\": 0.21301409602165222,\n",
    "            \"z\": -0.3438095450401306,\n",
    "            \"visibility\": 0.8915821313858032\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5938440561294556,\n",
    "            \"y\": 0.2152775377035141,\n",
    "            \"z\": -0.3432357907295227,\n",
    "            \"visibility\": 0.8881502747535706\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5961824655532837,\n",
    "            \"y\": 0.24234987795352936,\n",
    "            \"z\": -0.34266433119773865,\n",
    "            \"visibility\": 0.8926075100898743\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5731982588768005,\n",
    "            \"y\": 0.21209882199764252,\n",
    "            \"z\": -0.352565199136734,\n",
    "            \"visibility\": 0.898253858089447\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5733095407485962,\n",
    "            \"y\": 0.21431241929531097,\n",
    "            \"z\": -0.3517971634864807,\n",
    "            \"visibility\": 0.8994075059890747\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5739877820014954,\n",
    "            \"y\": 0.2128763347864151,\n",
    "            \"z\": -0.3512287139892578,\n",
    "            \"visibility\": 0.9117918014526367\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5697293877601624,\n",
    "            \"y\": 0.2675153315067291,\n",
    "            \"z\": -0.25576305389404297,\n",
    "            \"visibility\": 0.9092066884040833\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5450958013534546,\n",
    "            \"y\": 0.2680749297142029,\n",
    "            \"z\": -0.2955373525619507,\n",
    "            \"visibility\": 0.9304062724113464\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5863133668899536,\n",
    "            \"y\": 0.3318489193916321,\n",
    "            \"z\": -0.2829187214374542,\n",
    "            \"visibility\": 0.9342498779296875\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5599755644798279,\n",
    "            \"y\": 0.3260250389575958,\n",
    "            \"z\": -0.2969871461391449,\n",
    "            \"visibility\": 0.9371410608291626\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5801748037338257,\n",
    "            \"y\": 0.5935178399085999,\n",
    "            \"z\": -0.2736220061779022,\n",
    "            \"visibility\": 0.912200927734375\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.4459652304649353,\n",
    "            \"y\": 0.5696370005607605,\n",
    "            \"z\": -0.21251575648784637,\n",
    "            \"visibility\": 0.9175193309783936\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6751126050949097,\n",
    "            \"y\": 0.4636211097240448,\n",
    "            \"z\": -0.25243455171585083,\n",
    "            \"visibility\": 0.2201475352048874\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5622193217277527,\n",
    "            \"y\": 0.37807875871658325,\n",
    "            \"z\": -0.31541818380355835,\n",
    "            \"visibility\": 0.5996300578117371\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6549735069274902,\n",
    "            \"y\": 0.34549733996391296,\n",
    "            \"z\": -0.2163480520248413,\n",
    "            \"visibility\": 0.0974506288766861\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6559590101242065,\n",
    "            \"y\": 0.20786024630069733,\n",
    "            \"z\": -0.30346372723579407,\n",
    "            \"visibility\": 0.5821789503097534\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6463615894317627,\n",
    "            \"y\": 0.321217805147171,\n",
    "            \"z\": -0.2780008912086487,\n",
    "            \"visibility\": 0.11436416208744049\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.693077027797699,\n",
    "            \"y\": 0.187992662191391,\n",
    "            \"z\": -0.36558860540390015,\n",
    "            \"visibility\": 0.48644331097602844\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6419552564620972,\n",
    "            \"y\": 0.30604445934295654,\n",
    "            \"z\": -0.2915250062942505,\n",
    "            \"visibility\": 0.15957696735858917\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6841744780540466,\n",
    "            \"y\": 0.1734585165977478,\n",
    "            \"z\": -0.39454224705696106,\n",
    "            \"visibility\": 0.5455245971679688\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6478661298751831,\n",
    "            \"y\": 0.315883606672287,\n",
    "            \"z\": -0.22825300693511963,\n",
    "            \"visibility\": 0.1651751548051834\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.6640509963035583,\n",
    "            \"y\": 0.1808464080095291,\n",
    "            \"z\": -0.3227384090423584,\n",
    "            \"visibility\": 0.5639793276786804\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.5123761892318726,\n",
    "            \"y\": 1.687013030052185,\n",
    "            \"z\": -0.1400032490491867,\n",
    "            \"visibility\": 0.004396136850118637\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.4314190447330475,\n",
    "            \"y\": 1.7275233268737793,\n",
    "            \"z\": 0.14165827631950378,\n",
    "            \"visibility\": 0.006525450386106968\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.4721241593360901,\n",
    "            \"y\": 1.0836482048034668,\n",
    "            \"z\": -0.1921553760766983,\n",
    "            \"visibility\": 0.0274144746363163\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.3245542645454407,\n",
    "            \"y\": 1.0569993257522583,\n",
    "            \"z\": 0.08145172894001007,\n",
    "            \"visibility\": 0.01599154807627201\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.42380523681640625,\n",
    "            \"y\": 1.2012594938278198,\n",
    "            \"z\": 0.5203500986099243,\n",
    "            \"visibility\": 0.012692037038505077\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.39563223719596863,\n",
    "            \"y\": 1.0644021034240723,\n",
    "            \"z\": 0.5947502851486206,\n",
    "            \"visibility\": 0.013977599330246449\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.4009716510772705,\n",
    "            \"y\": 1.2437248229980469,\n",
    "            \"z\": 0.5071300864219666,\n",
    "            \"visibility\": 0.009529875591397285\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.39320793747901917,\n",
    "            \"y\": 1.079322338104248,\n",
    "            \"z\": 0.636406660079956,\n",
    "            \"visibility\": 0.015066493302583694\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.41117534041404724,\n",
    "            \"y\": 1.1338329315185547,\n",
    "            \"z\": 0.16041305661201477,\n",
    "            \"visibility\": 0.015477227047085762\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.39750704169273376,\n",
    "            \"y\": 0.9203481078147888,\n",
    "            \"z\": 0.44569554924964905,\n",
    "            \"visibility\": 0.01837105117738247\n",
    "        }\n",
    "    ],\n",
    "    \"ea\": [\n",
    "        {\n",
    "            \"x\": 0.09289216995239258,\n",
    "            \"y\": -0.6210291385650635,\n",
    "            \"z\": -0.08330655843019485,\n",
    "            \"visibility\": 0.8919544816017151\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09615056216716766,\n",
    "            \"y\": -0.6476690769195557,\n",
    "            \"z\": -0.08925311267375946,\n",
    "            \"visibility\": 0.8915821313858032\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09625852853059769,\n",
    "            \"y\": -0.6487014889717102,\n",
    "            \"z\": -0.0880894586443901,\n",
    "            \"visibility\": 0.8881502747535706\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09595300257205963,\n",
    "            \"y\": -0.6482436656951904,\n",
    "            \"z\": -0.0878986120223999,\n",
    "            \"visibility\": 0.8926075100898743\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09477884322404861,\n",
    "            \"y\": -0.6427960395812988,\n",
    "            \"z\": -0.09030025452375412,\n",
    "            \"visibility\": 0.898253858089447\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09505582600831985,\n",
    "            \"y\": -0.6437684297561646,\n",
    "            \"z\": -0.09140385687351227,\n",
    "            \"visibility\": 0.8994075059890747\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09400612860918045,\n",
    "            \"y\": -0.6452643275260925,\n",
    "            \"z\": -0.09028586745262146,\n",
    "            \"visibility\": 0.9117918014526367\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.08206788450479507,\n",
    "            \"y\": -0.6115298271179199,\n",
    "            \"z\": -0.07315720617771149,\n",
    "            \"visibility\": 0.9092066884040833\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.06100695580244064,\n",
    "            \"y\": -0.6052977442741394,\n",
    "            \"z\": -0.09453994780778885,\n",
    "            \"visibility\": 0.9304062724113464\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.07747616618871689,\n",
    "            \"y\": -0.5872812867164612,\n",
    "            \"z\": -0.07611992210149765,\n",
    "            \"visibility\": 0.9342498779296875\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.07349167764186859,\n",
    "            \"y\": -0.5837600231170654,\n",
    "            \"z\": -0.08128707855939865,\n",
    "            \"visibility\": 0.9371410608291626\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.08297406882047653,\n",
    "            \"y\": -0.46915847063064575,\n",
    "            \"z\": -0.0627308264374733,\n",
    "            \"visibility\": 0.912200927734375\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.00892446469515562,\n",
    "            \"y\": -0.4793561100959778,\n",
    "            \"z\": -0.07702311128377914,\n",
    "            \"visibility\": 0.9175193309783936\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.13862808048725128,\n",
    "            \"y\": -0.5210443139076233,\n",
    "            \"z\": -0.054063647985458374,\n",
    "            \"visibility\": 0.2201475352048874\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.09095865488052368,\n",
    "            \"y\": -0.5571553707122803,\n",
    "            \"z\": -0.08537811040878296,\n",
    "            \"visibility\": 0.5996300578117371\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.15426330268383026,\n",
    "            \"y\": -0.5839791297912598,\n",
    "            \"z\": -0.0596354715526104,\n",
    "            \"visibility\": 0.0974506288766861\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.14378727972507477,\n",
    "            \"y\": -0.6427748799324036,\n",
    "            \"z\": -0.07257787883281708,\n",
    "            \"visibility\": 0.5821789503097534\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.14889346063137054,\n",
    "            \"y\": -0.5860608220100403,\n",
    "            \"z\": -0.07307718694210052,\n",
    "            \"visibility\": 0.11436416208744049\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.16449372470378876,\n",
    "            \"y\": -0.6411864757537842,\n",
    "            \"z\": -0.08661572635173798,\n",
    "            \"visibility\": 0.48644331097602844\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.15136556327342987,\n",
    "            \"y\": -0.5933023691177368,\n",
    "            \"z\": -0.08239606767892838,\n",
    "            \"visibility\": 0.15957696735858917\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.1588146835565567,\n",
    "            \"y\": -0.644176185131073,\n",
    "            \"z\": -0.09475967288017273,\n",
    "            \"visibility\": 0.5455245971679688\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.1556403785943985,\n",
    "            \"y\": -0.5849223136901855,\n",
    "            \"z\": -0.06097546964883804,\n",
    "            \"visibility\": 0.1651751548051834\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.14925134181976318,\n",
    "            \"y\": -0.6400735974311829,\n",
    "            \"z\": -0.07864373177289963,\n",
    "            \"visibility\": 0.5639793276786804\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.04173381254076958,\n",
    "            \"y\": -0.0029893391765654087,\n",
    "            \"z\": -0.013512257486581802,\n",
    "            \"visibility\": 0.004396136850118637\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.041134659200906754,\n",
    "            \"y\": -0.007254003081470728,\n",
    "            \"z\": 0.014719926752150059,\n",
    "            \"visibility\": 0.006525450386106968\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.011308733373880386,\n",
    "            \"y\": -0.29514214396476746,\n",
    "            \"z\": -0.033202581107616425,\n",
    "            \"visibility\": 0.0274144746363163\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.09258024394512177,\n",
    "            \"y\": -0.34360286593437195,\n",
    "            \"z\": 0.027876390144228935,\n",
    "            \"visibility\": 0.01599154807627201\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.038051538169384,\n",
    "            \"y\": -0.3262351453304291,\n",
    "            \"z\": 0.1751028597354889,\n",
    "            \"visibility\": 0.012692037038505077\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.021609315648674965,\n",
    "            \"y\": -0.36210429668426514,\n",
    "            \"z\": 0.18663333356380463,\n",
    "            \"visibility\": 0.013977599330246449\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.03930986672639847,\n",
    "            \"y\": -0.3227757513523102,\n",
    "            \"z\": 0.19526518881320953,\n",
    "            \"visibility\": 0.009529875591397285\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.030160173773765564,\n",
    "            \"y\": -0.3622894287109375,\n",
    "            \"z\": 0.20780430734157562,\n",
    "            \"visibility\": 0.015066493302583694\n",
    "        },\n",
    "        {\n",
    "            \"x\": 0.016622375696897507,\n",
    "            \"y\": -0.4049746096134186,\n",
    "            \"z\": 0.05837491527199745,\n",
    "            \"visibility\": 0.015477227047085762\n",
    "        },\n",
    "        {\n",
    "            \"x\": -0.04433808475732803,\n",
    "            \"y\": -0.44549357891082764,\n",
    "            \"z\": 0.10847770422697067,\n",
    "            \"visibility\": 0.01837105117738247\n",
    "        }\n",
    "    ],\n",
    "    \"segmentationMask\": {},\n",
    "    \"multiFaceGeometry\": []\n",
    "}\n",
    "\n",
    "pyjson = AttrDict({\n",
    "    \"pose_landmarks\":{\n",
    "        \"landmark\":[]\n",
    "    },\n",
    "    \"left_hand_landmarks\":{\n",
    "        \"landmark\":[]\n",
    "    },\n",
    "    \"right_hand_landmarks\":{\n",
    "        \"landmark\":[]\n",
    "    }\n",
    "})\n",
    "\n",
    "pyjson[\"pose_landmarks\"][\"landmark\"] = j[\"poseLandmarks\"]\n",
    "if \"leftHandLandmarks\" in j:\n",
    "    pyjson[\"left_hand_landmarks\"][\"landmark\"] = j[\"leftHandLandmarks\"]\n",
    "if \"rightHandLandmarks\" in j:\n",
    "    pyjson[\"right_hand_landmarks\"][\"landmark\"] = j[\"rightHandLandmarks\"]\n",
    "\n",
    "\n",
    "print(keypointsToNumPy(pyjson).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('psupr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cff8dca6ddb8d9bfe57d04842b45276a848a5ef5b62e0470e5a9e5103929e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
