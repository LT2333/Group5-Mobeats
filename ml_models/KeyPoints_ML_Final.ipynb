{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a14985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from glob import glob\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9cab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time data augmentation\n",
    "# Move half of the test data to train -> train:test from 1:1 to 3:1\n",
    "import shutil\n",
    "def train_data_augmentation():\n",
    "    # move the last 30 examples from test to train\n",
    "    for each_class_path in all_class_path_test_new:\n",
    "        print(each_class_path)\n",
    "        for each_class in os.listdir(each_class_path):\n",
    "            print(os.path.join(each_class_path,each_class))\n",
    "            for i in os.listdir(os.path.join(each_class_path,each_class)):\n",
    "                if (int(i)>=30):\n",
    "                    print(int(i)+30)\n",
    "                    source = os.path.join(each_class_path,each_class,i)\n",
    "                    target = os.path.join(each_class_path.replace(\"newTest\",\"newTrain\"),each_class,str(int(i)+30))\n",
    "                    print(\"source:\",source)\n",
    "                    print(\"target:\",target)\n",
    "                    if os.path.exists(source):\n",
    "                        dest = shutil.move(source, target)\n",
    "                        print(dest)\n",
    "\n",
    "    print(\"Data reorg is done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af6b7d",
   "metadata": {},
   "source": [
    "## 1. Process data from MediaPipe Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9341baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \".\"\n",
    "data_path = os.path.join(folder_path, \"Data\")\n",
    "model_path = os.path.join(folder_path, \"Model\")\n",
    "# path health check\n",
    "assert os.path.exists(data_path) == True, \"data_path not exist: \"+data_path\n",
    "assert os.path.exists(model_path) == True, \"model_path not exist: \"+model_path\n",
    "\n",
    "# train_data = os.path.join(data_path,\"Train Data Augmentation\") \n",
    "# test_data = os.path.join(data_path,\"Test Data Augmentation\") \n",
    "train_data = os.path.join(data_path,\"newTrain\") \n",
    "test_data = os.path.join(data_path,\"newTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f008b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\Data\\\\newTrain\\\\CCW Rotate 15', '.\\\\Data\\\\newTrain\\\\CW Rotate 15', '.\\\\Data\\\\newTrain\\\\Left', '.\\\\Data\\\\newTrain\\\\Right', '.\\\\Data\\\\newTrain\\\\Zoom In', '.\\\\Data\\\\newTrain\\\\Zoom Out']\n",
      "num_classes 5\n",
      "['.\\\\Data\\\\newTest\\\\CCW Rotate 15', '.\\\\Data\\\\newTest\\\\CW Rotate 15', '.\\\\Data\\\\newTest\\\\Left', '.\\\\Data\\\\newTest\\\\Right', '.\\\\Data\\\\newTest\\\\Zoom In', '.\\\\Data\\\\newTest\\\\Zoom Out']\n"
     ]
    }
   ],
   "source": [
    "all_class_path_train = glob(os.path.join(train_data,\"*\"))\n",
    "all_class_path_test = glob(os.path.join(test_data,\"*\"))\n",
    "num_classes = 5\n",
    "print(all_class_path_train)\n",
    "print(\"num_classes\",num_classes)\n",
    "print(all_class_path_test)\n",
    "# train_data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cf658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Kiss': 0, 'Left_punch': 1, 'No_action': 2, 'Right_punch': 3, 'Wakanda': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list = ['Kiss', 'Left_punch', 'No_action', 'Right_punch', 'Wakanda']\n",
    "map_idx2class = {v: k for v, k in enumerate(class_list)}\n",
    "map_class2idx = { k:v for v, k in enumerate(class_list)}\n",
    "map_class2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0a5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def load_data(all_class_path, no_face=False):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    start = time.time()\n",
    "    # generate X_train, y_train from all the .npy files\n",
    "    for each_class_path in all_class_path:\n",
    "        print(each_class_path)\n",
    "        for name in os.listdir(each_class_path):\n",
    "            print(\"class_name: \"+name)\n",
    "            class_list = os.listdir(each_class_path+\"/\"+name)\n",
    "            for i in range(len(class_list)):\n",
    "                npylst = os.listdir(each_class_path+\"/\"+name+\"/\"+class_list[i])\n",
    "                for j in range(len(npylst)):\n",
    "                    if os.path.splitext(npylst[j])[1] == '.npy': # 筛选npy文件\n",
    "                        if no_face == False:\n",
    "                            arr =  np.load(each_class_path+\"/\"+name+\"/\"+class_list[i]+'/'+ npylst[j])\n",
    "                        else:\n",
    "                            arr_full =  np.load(each_class_path+\"/\"+name+\"/\"+class_list[i]+'/'+ npylst[j])\n",
    "                            arr = np.concatenate([arr_full[0:132],arr_full[1536:]])\n",
    "                        X_train.append( arr)\n",
    "                        y_train.append(map_class2idx.get(name))\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    print(\"Finish preparing X_train\")\n",
    "    end = time.time()\n",
    "    print(\"Time used: \",end - start)\n",
    "    print(X_train.shape)  \n",
    "    print(\"6 * 5 * 60 * 30 = \"+ str(6 * 5 * 60 * 30))\n",
    "    print(y_train.shape)\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd657a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Start preparing TRAINING data ######################################## \n",
      ".\\Data\\newTrain\\CCW Rotate 15\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTrain\\CW Rotate 15\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTrain\\Left\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTrain\\Right\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTrain\\Zoom In\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTrain\\Zoom Out\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      "Finish preparing X_train\n",
      "Time used:  26.489355325698853\n",
      "(81000, 258)\n",
      "6 * 5 * 60 * 30 = 54000\n",
      "(81000,)\n",
      "######################################## Start preparing TEST data ######################################## \n",
      ".\\Data\\newTest\\CCW Rotate 15\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTest\\CW Rotate 15\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTest\\Left\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTest\\Right\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTest\\Zoom In\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      ".\\Data\\newTest\\Zoom Out\n",
      "class_name: Kiss\n",
      "class_name: Left_punch\n",
      "class_name: No_action\n",
      "class_name: Right_punch\n",
      "class_name: Wakanda\n",
      "Finish preparing X_train\n",
      "Time used:  9.02134108543396\n",
      "(27000, 258)\n",
      "6 * 5 * 60 * 30 = 54000\n",
      "(27000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"######################################## Start preparing TRAINING data ######################################## \")\n",
    "X_train, y_train = load_data(all_class_path_train,no_face=True)\n",
    "print(\"######################################## Start preparing TEST data ######################################## \")\n",
    "X_test, y_test = load_data(all_class_path_test,no_face=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e555c70",
   "metadata": {},
   "source": [
    "## 2.Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb2548aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54000.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(81000+27000)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454409f4",
   "metadata": {},
   "source": [
    "## 2.1 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a25ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy of model at K=5 is 0.9866543209876544\n",
      "Test Accuracy of model at K=5 is 0.9398148148148148\n",
      "Time used:  135.81224632263184\n",
      "[[5285    0   14    0  101]\n",
      " [  11 5297   92    0    0]\n",
      " [ 298  238 4458  195  211]\n",
      " [   0   66   21 5313    0]\n",
      " [ 229    3   74   72 5022]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      5400\n",
      "           1       0.95      0.98      0.96      5400\n",
      "           2       0.96      0.83      0.89      5400\n",
      "           3       0.95      0.98      0.97      5400\n",
      "           4       0.94      0.93      0.94      5400\n",
      "\n",
      "    accuracy                           0.94     27000\n",
      "   macro avg       0.94      0.94      0.94     27000\n",
      "weighted avg       0.94      0.94      0.94     27000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "k = num_classes\n",
    "start = time.time()\n",
    "KNN = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "Pred_y = KNN.predict(X_train)\n",
    "\n",
    "print(\"Training Accuracy of model at K=5 is\",metrics.accuracy_score( y_train,Pred_y))\n",
    "y_pred = KNN.predict(X_test)\n",
    "print(\"Test Accuracy of model at K=5 is\",metrics.accuracy_score( y_test,y_pred))\n",
    "print(\"Time used: \",time.time() - start)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))  \n",
    "print(classification_report(y_test, y_pred)) \n",
    "get_prediction_time(KNN, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06f144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Prediction Time:  0.05199146270751953\n"
     ]
    }
   ],
   "source": [
    "get_prediction_time(KNN, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86316f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(KNN, open(os.path.join(model_path, \"KNN_Final\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0cc692",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566dc94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5263    0   37    0  100]\n",
      " [   0 5229  171    0    0]\n",
      " [ 139  127 5029   48   57]\n",
      " [   0   72   96 5232    0]\n",
      " [   0    0  311   66 5023]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      5400\n",
      "           1       0.96      0.97      0.97      5400\n",
      "           2       0.89      0.93      0.91      5400\n",
      "           3       0.98      0.97      0.97      5400\n",
      "           4       0.97      0.93      0.95      5400\n",
      "\n",
      "    accuracy                           0.95     27000\n",
      "   macro avg       0.96      0.95      0.95     27000\n",
      "weighted avg       0.96      0.95      0.95     27000\n",
      "\n",
      "0.9546666666666667\n",
      "Average Prediction Time:  0.040096092224121097\n",
      "Time used:  408.5349564552307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "rf_clf = RandomForestClassifier(n_estimators=500, random_state=0)  \n",
    "rf_clf.fit(X_train, y_train)  \n",
    "y_pred = rf_clf.predict(X_test) \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(metrics.accuracy_score(y_test, y_pred))  \n",
    "get_prediction_time(rf_clf, X_test)\n",
    "print(\"Time used: \",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77b20380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(rf_clf, open(os.path.join(model_path, \"RandomForest_Final\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0c75e2",
   "metadata": {},
   "source": [
    "### 2.3 AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "810e4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4666    0  632    0  102]\n",
      " [   0 4580  579   17  224]\n",
      " [ 898   80 4171  118  133]\n",
      " [   1   78  691 4567   63]\n",
      " [1255    0  696   77 3372]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      5400\n",
      "           1       0.97      0.85      0.90      5400\n",
      "           2       0.62      0.77      0.69      5400\n",
      "           3       0.96      0.85      0.90      5400\n",
      "           4       0.87      0.62      0.73      5400\n",
      "\n",
      "    accuracy                           0.79     27000\n",
      "   macro avg       0.82      0.79      0.80     27000\n",
      "weighted avg       0.82      0.79      0.80     27000\n",
      "\n",
      "0.790962962962963\n",
      "Average Prediction Time:  0.005983996391296387\n",
      "Time used:  97.76525902748108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start = time.time()\n",
    "ada = AdaBoostClassifier(n_estimators=60,learning_rate=1)\n",
    "ada.fit(X_train, y_train)  \n",
    "y_pred = ada.predict(X_test) \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "get_prediction_time(ada, X_test)\n",
    "print(\"Time used: \",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ea1ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5269    0   60    0   71]\n",
      " [   0 5136  243    0   21]\n",
      " [2038  178 3050   16  118]\n",
      " [   1   72  906 4376   45]\n",
      " [1554    0  150   72 3624]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.98      0.74      5400\n",
      "           1       0.95      0.95      0.95      5400\n",
      "           2       0.69      0.56      0.62      5400\n",
      "           3       0.98      0.81      0.89      5400\n",
      "           4       0.93      0.67      0.78      5400\n",
      "\n",
      "    accuracy                           0.79     27000\n",
      "   macro avg       0.83      0.79      0.80     27000\n",
      "weighted avg       0.83      0.79      0.80     27000\n",
      "\n",
      "0.7946296296296296\n",
      "Average Prediction Time:  0.0488757848739624\n",
      "Time used:  793.2772843837738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "start = time.time()\n",
    "ada = AdaBoostClassifier(n_estimators=500,learning_rate=1)\n",
    "ada.fit(X_train, y_train)  \n",
    "y_pred = ada.predict(X_test) \n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "get_prediction_time(ada, X_test)\n",
    "print(\"Time used: \",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b161dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(ada, open(os.path.join(model_path, \"AdaBoosting_Final\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff787476",
   "metadata": {},
   "source": [
    "### 2.4 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f302342e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4]), array([5564, 5541, 5325, 5470, 5100], dtype=int64))\n",
      "Accuracy: 0.9548148148148148\n",
      "\n",
      "Confusion Matrix:\n",
      "       0     1\n",
      "0  5295     0\n",
      "1     0  5310\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.952     0.981     0.966      5400\n",
      "           1      0.958     0.983     0.971      5400\n",
      "           2      0.921     0.909     0.915      5400\n",
      "           3      0.969     0.981     0.975      5400\n",
      "           4      0.975     0.921     0.947      5400\n",
      "\n",
      "    accuracy                          0.955     27000\n",
      "   macro avg      0.955     0.955     0.955     27000\n",
      "weighted avg      0.955     0.955     0.955     27000\n",
      "\n",
      "Average Prediction Time:  0.0\n",
      "Time used:  2.549647092819214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "start = time.time()\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "pred=lda.predict(X_test)\n",
    "print(np.unique(pred, return_counts=True))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, pred))  \n",
    "confmatrix = pd.DataFrame(confusion_matrix(pred, y_test, labels=[0,1]), index=[0,1])\n",
    "print(\"\\nConfusion Matrix:\\n\", confmatrix)\n",
    "print('\\n')\n",
    "print(classification_report(y_test, pred, digits=3))\n",
    "get_prediction_time(lda, X_test)\n",
    "\n",
    "print(\"Time used: \",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "852e6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(lda, open(os.path.join(model_path, \"LDA_Final\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e05d0",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a4ed739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_time(model, X_test):\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(10):\n",
    "        y_pred = model.predict([X_test[i]])\n",
    "    end = time.time()\n",
    "    print(\"Average Prediction Time: \",(end - start)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae990e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Zhao Lutong"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "title": "KeyPoints_ML_Final"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
